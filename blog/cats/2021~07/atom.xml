<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: 2021~07 | kk Blog —— 通用基础]]></title>
  <link href="http://abcdxyzk.github.io/blog/cats/2021~07/atom.xml" rel="self"/>
  <link href="http://abcdxyzk.github.io/"/>
  <updated>2025-07-21T17:22:06+08:00</updated>
  <id>http://abcdxyzk.github.io/</id>
  <author>
    <name><![CDATA[kk]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[磁盘 partx，lsblk，blkid，partprobe]]></title>
    <link href="http://abcdxyzk.github.io/blog/2021/07/21/partx-lsblk/"/>
    <updated>2021-07-21T14:00:00+08:00</updated>
    <id>http://abcdxyzk.github.io/blog/2021/07/21/partx-lsblk</id>
    <content type="html"><![CDATA[<p><a href="https://blog.csdn.net/qq_36462472/article/details/84106868">https://blog.csdn.net/qq_36462472/article/details/84106868</a></p>

<h3>总结</h3>

<p>在使用fdisk命令创建分区后，可以使用partx和partprobe使系统内核加载分区信息，然后使用lsblk或partx -s 设备名 查看修改后的设备分区信息，给分区做上文件系统后，可以使用blkid命令查看设备信息，以及其文件系统等信息。</p>

<p>使用<code>partx -s /</code> <code>partx -l</code> 查看分区信息如果出错，可能是信息未被登记，可使用partx -a 设备名 来添加，再进行查看。</p>

<h3>patrx</h3>

<p>修改磁盘分区表后，无需重启，用partx命令告诉内核，分区已改动，内核可以读入新的分区表信息</p>

<p>/proc/partitions 记录了系统中所有硬盘及其上面的分区，包括已挂载和未挂载的。</p>

<p>有些硬盘没有记录分区信息，可能是没有分区，也可能是未记录</p>

<p>对于分区完成，但是尚未挂载的硬盘分区，partx告诉内核去做登记，已备挂载。</p>

<p>partx告诉内核去识别，登记某个硬盘上的分区信息。并不是加载，只是识别并记录而已，或者删除某个分区的信息。</p>

<pre><code>    [root@localhost ~]# partx --help

    Usage:
     partx [-a|-d|-s|-u] [--nr &lt;n:m&gt; | &lt;partition&gt;] &lt;disk&gt;

    Options:
     -a, --add            add specified partitions or all of them
     -d, --delete         delete specified partitions or all of them
     -s, --show           list partitions

     -u, --update         update specified partitions or all of them
     -b, --bytes          print SIZE in bytes rather than in human readable format
     -g, --noheadings     don't print headings for --show
     -n, --nr &lt;n:m&gt;       specify the range of partitions (e.g. --nr 2:4)
     -o, --output &lt;type&gt;  define which output columns to use
     -P, --pairs          use key="value" output format
     -r, --raw            use raw output format
     -t, --type &lt;type&gt;    specify the partition type (dos, bsd, solaris, etc.)
     -v, --verbose        verbose mode

     -h, --help     display this help and exit
     -V, --version  output version information and exit

    Available columns (for --show, --raw or --pairs):
             NR  partition number
          START  start of the partition in sectors
            END  end of the partition in sectors
        SECTORS  number of sectors
           SIZE  human readable size
           NAME  partition name
           UUID  partition UUID
           TYPE  partition type hex or uuid
          FLAGS  partition flags
         SCHEME  partition table type (dos, gpt, ...)

    For more details see partx(8).
</code></pre>

<pre><code>    partx命令：
        -a 设备： 登记某块盘上的所有分区信息。如果分区信息有记录，则报错。
        -d 设备： 删除内核中关于某磁盘的所有分区的记录。（不是卸载）
        -s 设备 ：显示磁盘的分区信息
</code></pre>

<p>通过partx工具让内核重读磁盘分区表信息：</p>

<pre><code>    partx -d /dev/sdb  #因为内核中存在部分未调整磁盘的信息，故先将所有信息清零
    partx -a /dev/sdb  #添加调整后的磁盘分区信息
    partx -s /dev/sdb  #显示磁盘分区信息

    NR   START       END   SECTORS SIZE NAME UUID
     1    2048   2099199   2097152   1G      
     2 2099200 419430399 417331200 199G
</code></pre>

<h3>lsblk命令</h3>

<p>列出所有可用块设备的信息，而且还能显示他们之间的依赖关系，但是它不会列出RAM盘的信息。块设备有硬盘，闪存盘，CD-ROM等等。</p>

<p>lsblk -f 也可以查看 UUID</p>

<p>lsblk和df的区别：</p>

<p>lsblk 查看的是block device，也就是逻辑磁盘的大小</p>

<p>df 查看的是file system，也就是文件系统层的磁盘大小，并且已挂载</p>

<pre><code>    [root@localhost ~]# lsblk -f
    NAME            FSTYPE      LABEL           UUID                                   MOUNTPOINT
    sda                                                                                
    ├─sda1          xfs                         f19cfd60-9c16-4ef9-bebf-a173e11ff163   /boot
    └─sda2          LVM2_member                 ZTRWNx-aK5p-U1by-k0ek-B66L-hIzo-i69WzG 
      ├─centos-root xfs                         1c43a251-c82f-47f2-ac60-5674f8590883   /
      ├─centos-swap swap                        77b30510-cc6c-40e6-a739-57d44fc0f751   [SWAP]
      └─centos-home xfs                         7dcba2d9-4955-4f54-886a-4687969e84dd   /home
    sr0             iso9660     VBox_GAs_6.1.16 2020-10-15-14-48-48-14
</code></pre>

<pre><code>    NAME ：这是块设备名。
    MAJ:MIN ：本栏显示主要和次要设备号。
    RM ：本栏显示设备是否可移动设备。注意，在本例中设备sdb和sr0的RM值等于1，这说明他们是可移动设备。
    SIZE ：本栏列出设备的容量大小信息。例如298.1G表明该设备大小为298.1GB，而1K表明该设备大小为1KB。
    RO ：该项表明设备是否为只读。在本案例中，所有设备的RO值为0，表明他们不是只读的。
    TYPE ：本栏显示块设备是否是磁盘或磁盘上的一个分区。在本例中，sda和sdb是磁盘，而sr0是只读存储（rom）。
    MOUNTPOINT ：本栏指出设备挂载的挂载点。
</code></pre>

<h3>blkid命令</h3>

<p>显示关于可用块设备的信息，他可以识别一个块设备内容的类别（如文件系统，交换区）以及从内容的元数据（如卷标或UUID字段）中获取属性（如tokens和键值对）。它主要有两类作用：用指定的键值对搜索一个设备，或是显示一个或多个设备的键值对。</p>

<p>不添加任何参数直接运行blkid将会输出所有可用的设备，他们的通用唯一识别码（UUID），文件系统类型以及卷标（如果有设置过）</p>

<pre><code>    [root@localhost ~]# blkid
    /dev/sr0: UUID="2020-10-15-14-48-48-14" LABEL="VBox_GAs_6.1.16" TYPE="iso9660" 
    /dev/sda1: UUID="f19cfd60-9c16-4ef9-bebf-a173e11ff163" TYPE="xfs" 
    /dev/sda2: UUID="ZTRWNx-aK5p-U1by-k0ek-B66L-hIzo-i69WzG" TYPE="LVM2_member" 
    /dev/mapper/centos-root: UUID="1c43a251-c82f-47f2-ac60-5674f8590883" TYPE="xfs" 
    /dev/mapper/centos-swap: UUID="77b30510-cc6c-40e6-a739-57d44fc0f751" TYPE="swap" 
    /dev/mapper/centos-home: UUID="7dcba2d9-4955-4f54-886a-4687969e84dd" TYPE="xfs"
</code></pre>

<h3>partprobe</h3>

<p>通知系统分区表的变化</p>

<p>使用fdisk或其他命令创建一个新的分区，然后使用partprobe命令重新读取分区表。这个命令执行完毕后不会输出任何返回信息。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[resuce 模式中mount fail]]></title>
    <link href="http://abcdxyzk.github.io/blog/2021/07/21/mount-fail/"/>
    <updated>2021-07-21T13:55:00+08:00</updated>
    <id>http://abcdxyzk.github.io/blog/2021/07/21/mount-fail</id>
    <content type="html"><![CDATA[<p><a href="https://www.dell.com/support/kbdoc/zh-cn/000181978/appsync-service-plan-failed-in-mount-copy-phase">https://www.dell.com/support/kbdoc/zh-cn/000181978/appsync-service-plan-failed-in-mount-copy-phase</a></p>

<h2>症状</h2>

<h4>Error in Host OS message log file:</h4>

<pre><code>    kernel: XFS (dm-32): Superblock has unknown read-only compatible features (0x4) enabled.
    kernel: XFS (dm-32): Attempted to mount read-only compatible filesystem read-write.
    kernel: XFS (dm-32): Filesystem can only be safely mounted read only.
    kernel: XFS (dm-32): SB validate failed with error -22.
</code></pre>

<h4>From Host OS dmesg log file:</h4>

<pre><code>    [ 8.529818] XFS (dm-7): Mounting V5 Filesystem
    [ 8.530257] XFS (dm-8): Mounting V5 Filesystem
    [ 8.557572] XFS (dm-7): Ending clean mount
    [ 9.253626] XFS (dm-8): Ending clean mount
</code></pre>

<h4>Events logs:</h4>

<pre><code>    Mount copy MILE_000002,&lt;AppSync Host&gt;,Error occurred during the execution of service plan &lt;Service Plan name&gt;
    Mount copy HST_000065,&lt;AppSync Host&gt;,Failed to discover fc and iscsi adapter information on host &lt;Mount Host&gt;
    Mount copy UNIX_000009,&lt;Mount Host&gt;,Rescan command failed on the host.
</code></pre>

<h4>Mount Host logs:</h4>

<pre><code>    acputil.py[647]:execute() Info:Running command: mount -t xfs -o nouuid,rw,relatime,attr2,inode64,noquota &lt;FS&gt;

    host.py[4121]:mount() Error caught during mount: : ['mount: wrong fs type, bad option, bad superblock on &lt;FS&gt;,', ' missing codepage or helper program, or other error', '', ' In some cases useful info is found in syslog - try', ' dmesg | tail or so.'] 
</code></pre>

<h2>原因</h2>

<p>RHEL bug triggered by unsupported configuration of not matching the source and mount hosts OS version.</p>

<h2>解决方案</h2>

<p>In this case, user was on Higher Source Host version (RHEL 8) and in lower Mount host version (RHEL 7.9). User made a new mount host matching to Source host and Service Plan ran fine.</p>

<h2>其他信息</h2>

<p>After doing some google search, it seem to be an issue with XFS v5 filesystem. Some of the important points are:</p>

<p>a) XFS filesystem is using XFS v5 (as per the dmesg logs) and contains features not supported by the RHEL7 kernel.</p>

<p>b) As per RHEL <a href="https://access.redhat.com/solutions/4582401,">https://access.redhat.com/solutions/4582401,</a> we need to create the filesystem without the reflink feature to use a XFS filesystem in both RHEL 7 and RHEL 8. Customer is on RHEL 7.9.
mkfs.xfs -m reflink=0 /dev/sdN</p>

<p>To avoid the error, “-m reflink=0” is needed which disables the incompatible copy-on-right reflink support.</p>

<p>Source:- <a href="https://www.humblec.com/ceph-csi-xfs-superblock-has-unknown-read-only-or-wrong-fs-type-bad-on-dev-rbd4-missing-codepage-or/">https://www.humblec.com/ceph-csi-xfs-superblock-has-unknown-read-only-or-wrong-fs-type-bad-on-dev-rbd4-missing-codepage-or/</a></p>

<p>c) mkfs.xfs (starting with version 3.2.4 of xfsprogs) recently defaulted to version 5 superblock, with lots of new enhancements like metadata CRC checksums. Version 5 superblock requires a 3.16 kernel or better. This error is typical, you&rsquo;re trying to mount the volume on a kernel which doesn&rsquo;t support v5 superblocks, i. e. with a version prior to 3.16.</p>

<p>Be careful, when using recent versions of xfsprogs with older kernels. You&rsquo;ll have to use these options to create a v4 filesystem:
mkfs.xfs -m crc=0,finobt=0 /your/device</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[xfs文件系统修复 xfs_repair]]></title>
    <link href="http://abcdxyzk.github.io/blog/2021/07/20/xfs_repair/"/>
    <updated>2021-07-20T16:53:00+08:00</updated>
    <id>http://abcdxyzk.github.io/blog/2021/07/20/xfs_repair</id>
    <content type="html"><![CDATA[<p><a href="https://blog.csdn.net/theoldsod2000/article/details/105988902/">https://blog.csdn.net/theoldsod2000/article/details/105988902/</a></p>

<p>因为断电等原因可能无法开机，提示
<code>
    Failed to start Remount Root and Kenal File System
</code></p>

<p>可以通过xfs_repair命令进行修复。</p>

<pre><code>    [root@localhost ~]# xfs_repair
    Usage: xfs_repair [options] device

    Options:
      -f           The device is a file
      -L           Force log zeroing. Do this as a last resort.
      -l logdev    Specifies the device where the external log resides.
      -m maxmem    Maximum amount of memory to be used in megabytes.
      -n           No modify mode, just checks the filesystem for damage.
      -P           Disables prefetching.
      -r rtdev     Specifies the device where the realtime section resides.
      -v           Verbose output.
      -c subopts   Change filesystem parameters - use xfs_admin.
      -o subopts   Override default behaviour, refer to man page.
      -t interval  Reporting interval in seconds.
      -d           Repair dangerously.
      -V           Reports version and exits.
</code></pre>

<p>xfs_repair最重要的是指定要修复的设备</p>

<p>如果是LVM管理分区的</p>

<p>可以通过 ls -l   /dev/mapper 来查看可用的设备。</p>

<p>一般可以看到2到3个链接文件，centos-home -> ../dm-1, centos-root->../dm-0</p>

<p>执行xfs_repair /dev/dm-0 正常情况下，这个分区就修复好了，再接着执行 xfs_repair  /dev/dm-1，正常情况下，这个分区也会修复好。</p>

<p>如果不是LVM分区管理的，可以 通过 ls /dev  查看，一般会有sda,sda1,sda2.</p>

<p>可以执行 xfs_repair /dev/sda1  和 xfs_repair /dev/sda2 进行修复。</p>

<p>如果修复失败，可以加上  -L  参数，这样可能会丢失部分数据。</p>

<p>修复的过程中可能会出错，提示找不到superblock。</p>

<p>下面这篇文章很清楚的讲述了superblock，inode，block的关系，可以帮助我们理解</p>

<p> <a href="https://blog.csdn.net/Ohmyberry/article/details/80427492">https://blog.csdn.net/Ohmyberry/article/details/80427492</a></p>

<p> dm是device mapper的意思,主要涉及的linux下卷的管理。卷管理通过映射的方法建立了逻辑卷。每个逻辑卷相当于一个分区。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Linux下挂载lvm 重名问题]]></title>
    <link href="http://abcdxyzk.github.io/blog/2021/07/20/LVM2/"/>
    <updated>2021-07-20T16:47:00+08:00</updated>
    <id>http://abcdxyzk.github.io/blog/2021/07/20/LVM2</id>
    <content type="html"><![CDATA[<p><a href="https://blog.51cto.com/songxj/269661">https://blog.51cto.com/songxj/269661</a></p>

<p>linux下使用新硬盘安装系统，安装好以后再挂载原来的硬盘，分区格式全为系统默认分区，系统默认使用的是lvm格式，并且默认的卷都是 VolGroup00</p>

<p>使用 pvs 查看显示如下：
<code>
    [root@localhost ~]# pvs
    PV VG Fmt Attr PSize PFree
    /dev/sda2 VolGroup00 lvm2 a- 136.62G 0
    /dev/sdb2 VolGroup00 lvm2 a- 136.62G 0
</code>
发现可以正确认别到两个VG，但是同名，如何挂载呢？</p>

<h4>解决办法是，将原来的VG更名，解决冲突即可挂载。</h4>

<p>重命名格式为：
<code>
    vgrename VolGroup00 VolGroup01
</code>
此时会提示：
<code>
    [root@localhost ~]# vgrename VolGroup00 VolGroup01
    Found more than one VG called VolGroup00. Please supply VG uuid.
</code>
原因是存在两个 VolGroup00，修改的方法他已经提示了要指定 VG uuid即可。</p>

<p>查看VG uuid的命令为：
<code>
    [root@localhost ~]# vgs -v
    Finding all volume groups
    Finding volume group "VolGroup00"
    Finding volume group "VolGroup00"
    VG Attr Ext #PV #LV #SN VSize VFree VG UUID
    VolGroup00 wz--n- 32.00M 1 2 0 136.62G 0 dcHa6G-abU2-Xfq8-EPBm-jBLj-sf18-O5uH0U
    VolGroup00 wz--n- 32.00M 1 2 0 136.62G 0 OF8g7h-PQJB-9D9z-yPxn-1kfY-Advq-YbNHJ9
</code></p>

<p>查到VG uuid以后，再次执行改名：
<code>
    [root@localhost ~]# vgrename OF8g7h-PQJB-9D9z-yPxn-1kfY-Advq-YbNHJ9 VolGroup01
    Volume group "VolGroup00" still has active LVs
</code></p>

<p>修改成功以后，再执行：lvscan
<code>
    [root@localhost ~]# lvscan
    inactive '/dev/VolGroup01/LogVol00' [130.84 GB] inherit
    inactive '/dev/VolGroup01/LogVol01' [5.78 GB] inherit
    ACTIVE '/dev/VolGroup00/LogVol00' [130.84 GB] inherit
    ACTIVE '/dev/VolGroup00/LogVol01' [5.78 GB] inherit
</code></p>

<p>可以看到新修改的VolGroup01是inactive状态。</p>

<p>再使用vgchange 加载 VolGroup01
<code>
    [root@localhost ~]# vgchange -ay /dev/VolGroup01
    2 logical volume(s) in volume group "VolGroup01" now active
</code></p>

<p>最后 mount 就可以
<code>
    [root@localhost ~]# mount /dev/VolGroup01/LogVol00 /mnt/old
</code></p>

<p>至此，全部完成。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[创建和管理LVM]]></title>
    <link href="http://abcdxyzk.github.io/blog/2021/07/20/LVM1/"/>
    <updated>2021-07-20T16:38:00+08:00</updated>
    <id>http://abcdxyzk.github.io/blog/2021/07/20/LVM1</id>
    <content type="html"><![CDATA[<p><a href="https://www.cnblogs.com/zuizui1204/p/10044945.html">https://www.cnblogs.com/zuizui1204/p/10044945.html</a></p>

<p><a href="https://blog.csdn.net/qq_20745901/article/details/54575586">https://blog.csdn.net/qq_20745901/article/details/54575586</a></p>

<h4>1、 创建分区</h4>

<p>使用fdisk 创建LVM分区，方法和创建其他一般分区的方式是一样的，区别仅仅是LVM的分区类型为8e。</p>

<p><img src="/images/system/20210720-21.png" alt="" /></p>

<h4>2、创建PV</h4>

<pre><code>    pvcreate /dev/sdb1
</code></pre>

<h4>3、创建VG：</h4>

<p>先查看已经存在的VG</p>

<p>vgs和vgdispaly：vgs信息较少，vgdisplay信息较多</p>

<p>可以看到已经存在了一个VG：vg_zjhzmodelredh</p>

<p>新建
<code>
    vgcreate vgName /dev/sdb1
</code></p>

<p>这里新增已经存在的VG：
<code>
    vgextend vg_zjhzmodelredh /dev/sdb1
</code></p>

<p><img src="/images/system/20210720-22.png" alt="" /></p>

<p>创建完成VG之后，才能从VG中划分一个LV。</p>

<h4>4、创建LV</h4>

<p>命令：
<code>
    lvcreate -L 大小 -n lvName VGName
</code></p>

<p><img src="/images/system/20210720-23.png" alt="" /></p>

<h4>5、LV格式化及挂载</h4>

<p>如未激活，需要激活逻辑卷：
<code>
    vgchange -ay /dev/VolGroup00
</code></p>

<p>下一步需要对LV进行格式化（使用mkfs进行格式化操作），然后LV才能存储资料</p>

<pre><code>    mkfs -t ext4 /dev/vg_zjhzmodelredh/data
</code></pre>

<p>将格式化后的LV分区挂载到指定的目录下，就可以像普通目录一样存储数据了</p>

<p>挂载之后，可以看到此LV的容量。</p>

<p>如果要在系统启动的时候启动LV，最好是将lvData写入fstab</p>
]]></content>
  </entry>
  
</feed>
