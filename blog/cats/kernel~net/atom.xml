<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: kernel~net | kk Blog —— 通用基础]]></title>
  <link href="http://abcdxyzk.github.io/blog/cats/kernel~net/atom.xml" rel="self"/>
  <link href="http://abcdxyzk.github.io/"/>
  <updated>2023-01-24T19:27:19+08:00</updated>
  <id>http://abcdxyzk.github.io/</id>
  <author>
    <name><![CDATA[kk]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Linux内核之GRE处理分析]]></title>
    <link href="http://abcdxyzk.github.io/blog/2022/11/27/kernel-gre/"/>
    <updated>2022-11-27T20:47:00+08:00</updated>
    <id>http://abcdxyzk.github.io/blog/2022/11/27/kernel-gre</id>
    <content type="html"><![CDATA[<p><a href="https://blog.csdn.net/s2603898260/article/details/115773153">https://blog.csdn.net/s2603898260/article/details/115773153</a></p>

<p><a href="https://blog.csdn.net/u014044624/article/details/106596000">https://blog.csdn.net/u014044624/article/details/106596000</a></p>

<p><img src="/images/kernel/20221127-31.png" alt="" /></p>

<hr />

<h2>GRE</h2>

<p>GRE（Generic Routing Encapsulation，通用路由封装）协议是对某些网络层协议（如IP 和IPX）的数据报文进行封装，使这些被封装的数据报文能够在另一个网络层协议（如IP）中传输。</p>

<p>在大多数常规情况下，系统拥有一个有效载荷（或负载）包，需要将它封装并发送至某个目的地。首先将有效载荷封装在一个 GRE 包中，然后将此 GRE 包封装在其它某协议中并进行转发。此外发协议即为发送协议。当 IPv4 被作为 GRE 有效载荷传输时，协议类型字段必须被设置为 0x800 。当一个隧道终点拆封此含有 IPv4 包作为有效载荷的 GRE 包时， IPv4 包头中的目的地址必须用来转发包，并且需要减少有效载荷包的 TTL 。值得注意的是，在转发这样一个包时，如果有效载荷包的目的地址就是包的封装器（也就是隧道另一端），就会出现回路现象。在此情形下，必须丢弃该包。当 GRE 包被封装在 IPv4 中时，需要使用 IPv4 协议 47 。</p>

<p><img src="/images/kernel/20221127-32.png" alt="" /></p>

<p>GRE采用了Tunnel（隧道）技术，是VPN（Virtual Private Network）的第三层隧道协议。Tunnel 是一个虚拟的点对点的连接，提供了一条通路使封装的数据报文能够在这个通路上传输，并且在一个Tunnel 的两端分别对数据报进行封装及解封装。</p>

<p><img src="/images/kernel/20221127-33.png" alt="" /></p>

<h3>GRE包发送过程：</h3>

<p>发送过程是很简单的，因为 router A 上配置了一条路由规则，凡是发往 10.0.2.0 网络的包都要经过 netb 这个 tunnel 设备，在内核中经过 forward 之后就最终到达这个 GRE tunnel 设备的 ndo_start_xmit()，也就是 ipgre_tunnel_xmit() 函数。这个函数所做的事情无非就是通过 tunnel 的 header_ops 构造一个新的头，并把对应的外部 IP 地址填进去，最后发送出去。</p>

<h4>Linux kernel函数调用分析：</h4>

<p><img src="/images/kernel/20221127-34.png" alt="" /></p>

<h3>GRE包接收过程：</h3>

<p>接收过程，即 router B 上面进行的操作。这里需要指出的一点是，GRE tunnel 自己定义了一个新的 IP proto，也就是 IPPROTO_GRE。当 router B 收到从 router A 过来的这个包时，它暂时还不知道这个是 GRE 的包，它首先会把它当作普通的 IP 包处理。因为外部的 IP 头的目的地址是该路由器的地址，所以它自己会接收这个包，把它交给上层，到了 IP 层之后才发现这个包不是 TCP，UDP，而是 GRE，这时内核会转交给 GRE 模块处理。</p>

<p>ipgre_rcv() 所做的工作是：通过外层IP 头找到对应的 tunnel，然后剥去外层 IP 头，把这个“新的”包重新交给 IP 栈去处理，像接收到普通 IP 包一样。到了这里，“新的”包处理和其它普通的 IP 包已经没有什么两样了：根据 IP 头中目的地址转发给相应的 host。</p>

<p>注：在这里可以把gre当做L4层协议。</p>

<h4>Linux kernel函数调用分析：</h4>

<p><img src="/images/kernel/20221127-35.png" alt="" /></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Linux nf_conntrack连接跟踪的实现]]></title>
    <link href="http://abcdxyzk.github.io/blog/2022/11/27/nf-conntrack/"/>
    <updated>2022-11-27T20:09:00+08:00</updated>
    <id>http://abcdxyzk.github.io/blog/2022/11/27/nf-conntrack</id>
    <content type="html"><![CDATA[<p><a href="http://bbs.chinaunix.net/thread-4082396-1-1.html">http://bbs.chinaunix.net/thread-4082396-1-1.html</a></p>

<p>连接跟踪，顾名思义，就是识别一个连接上双方向的数据包，同时记录状态。下面看一下它的数据结构：</p>

<pre><code>    struct nf_conn {
        /* Usage count in here is 1 for hash table/destruct timer, 1 per skb, plus 1 for any connection(s) we are `master' for */
        struct  nf_conntrack  ct_general;       /* 连接跟踪的引用计数 */
        spinlock_t  lock;

        /* Connection tracking(链接跟踪)用来跟踪、记录每个链接的信息(目前仅支持IP协议的连接跟踪)。
            每个链接由“tuple”来唯一标识，这里的“tuple”对不同的协议会有不同的含义，例如对tcp,udp
             来说就是五元组: (源IP，源端口，目的IP, 目的端口，协议号)，对ICMP协议来说是: (源IP, 目
            的IP, id, type, code), 其中id,type与code都是icmp协议的信息。链接跟踪是防火墙实现状态检
            测的基础，很多功能都需要借助链接跟踪才能实现，例如NAT、快速转发、等等。*/
        struct  nf_conntrack_tuple_hash  tuplehash[IP_CT_DIR_MAX];

        unsigned long  status;                 /* 可以设置由enum ip_conntrack_status中描述的状态 */

        struct  nf_conn  *master;           /* 如果该连接是某个连接的子连接，则master指向它的主连接 */
        /* Timer function; drops refcnt when it goes off. */
        struct  timer_list  timeout;

        union nf_conntrack_proto proto;     /* 用于保存不同协议的私有数据 */
        /* Extensions */
        struct nf_ct_ext *ext;          /* 用于扩展结构 */
    };
</code></pre>

<p>这个结构非常简单，其中最主要的就是tuplehash（跟踪连接双方向数据）和status（记录连接状态），这也连接跟踪最主要的功能。</p>

<p>在status中可以设置的标志，由下面的enum ip_conntrack_status描述，它们可以共存。这些标志设置后就不会再被清除。</p>

<pre><code>    enum ip_conntrack_status {
        IPS_EXPECTED_BIT = 0,       /* 表示该连接是个子连接 */
        IPS_SEEN_REPLY_BIT = 1,     /* 表示该连接上双方向上都有数据包了 */
        IPS_ASSURED_BIT = 2,        /* TCP：在三次握手建立完连接后即设定该标志。UDP：如果在该连接上的两个方向都有数据包通过，
                                    则再有数据包在该连接上通过时，就设定该标志。ICMP：不设置该标志 */
        IPS_CONFIRMED_BIT = 3,      /* 表示该连接已被添加到net-&gt;ct.hash表中 */
        IPS_SRC_NAT_BIT = 4,        /*在POSTROUTING处，当替换reply tuple完成时, 设置该标记 */
        IPS_DST_NAT_BIT = 5,        /* 在PREROUTING处，当替换reply tuple完成时, 设置该标记 */
        /* Both together. */
        IPS_NAT_MASK = (IPS_DST_NAT | IPS_SRC_NAT),
        /* Connection needs TCP sequence adjusted. */
        IPS_SEQ_ADJUST_BIT = 6,
        IPS_SRC_NAT_DONE_BIT = 7,   /* 在POSTROUTING处，已被SNAT处理，并被加入到bysource链中，设置该标记 */
        IPS_DST_NAT_DONE_BIT = 8,   /* 在PREROUTING处，已被DNAT处理，并被加入到bysource链中，设置该标记 */
        /* Both together */
        IPS_NAT_DONE_MASK = (IPS_DST_NAT_DONE | IPS_SRC_NAT_DONE),
        IPS_DYING_BIT = 9,      /* 表示该连接正在被释放，内核通过该标志保证正在被释放的ct不会被其它地方再次引用。有了这个标志，当某个连接要被删除时，即使它还在net-&gt;ct.hash中，也不会再次被引用。*/
        IPS_FIXED_TIMEOUT_BIT = 10, /* 固定连接超时时间，这将不根据状态修改连接超时时间。通过函数nf_ct_refresh_acct()修改超时时间时检查该标志。 */
        IPS_TEMPLATE_BIT = 11,      /* 由CT target进行设置（这个target只能用在raw表中，用于为数据包构建指定ct，并打上该标志），用于表明这个ct是由CT target创建的 */
    };
</code></pre>

<p>连接跟踪对该连接上的每个数据包表现为以下几种状态之一，由enum ip_conntrack_info表示，被设置在skb->nfctinfo中。
<code>
    enum ip_conntrack_info {
        IP_CT_ESTABLISHED（0）,    /* 表示这个数据包对应的连接在两个方向都有数据包通过，并且这是ORIGINAL初始方向数据包（无论是TCP、UDP、ICMP数据包，只要在该连接的两个方向上已有数据包通过，就会将该连接设置为IP_CT_ESTABLISHED状态。不会根据协议中的标志位进行判断，例如TCP的SYN等）。但它表示不了这是第几个数据包，也说明不了这个CT是否是子连接。*/
        IP_CT_RELATED（1）,       /* 表示这个数据包对应的连接还没有REPLY方向数据包，当前数据包是ORIGINAL方向数据包。并且这个连接关联一个已有的连接，是该已有连接的子连接，（即status标志中已经设置了IPS_EXPECTED标志，该标志在init_conntrack()函数中设置）。但无法判断是第几个数据包（不一定是第一个）*/
        IP_CT_NEW（2）,           /* 表示这个数据包对应的连接还没有REPLY方向数据包，当前数据包是ORIGINAL方向数据包，该连接不是子连接。但无法判断是第几个数据包（不一定是第一个）*/
        IP_CT_IS_REPLY（3）,      /* 这个状态一般不单独使用，通常以下面两种方式使用 */
        IP_CT_ESTABLISHED + IP_CT_IS_REPLY（3）,  /* 表示这个数据包对应的连接在两个方向都有数据包通过，并且这是REPLY应答方向数据包。但它表示不了这是第几个数据包，也说明不了这个CT是否是子连接。*/
        IP_CT_RELATED + IP_CT_IS_REPLY（4）,      /* 这个状态仅在nf_conntrack_attach()函数中设置，用于本机返回REJECT，例如返回一个ICMP目的不可达报文， 或返回一个reset报文。它表示不了这是第几个数据包。*/
        IP_CT_NUMBER = IP_CT_IS_REPLY * 2 - 1（5）    /* 可表示状态的总数 */
    };
</code></p>

<p>以上就是连接跟踪里最重要的数据结构了，用于跟踪连接、记录状态、并对该连接的每个数据包设置一种状态。</p>

<p>除了上面的主要数据结构外，还有一些辅助数据结构，用于处理不同协议的私有信息、处理子连接、对conntrack进行扩展等。</p>

<h4>三层协议（IPv4/IPv6）</h4>

<p>利用nf_conntrack_proto.c文件中的
<code>
    nf_conntrack_l3proto_register(struct nf_conntrack_l3proto *proto)
    和
    nf_conntrack_l3proto_unregister(struct nf_conntrack_l3proto *proto)
</code>
在nf_ct_l3protos[]数组中注册自己的三层协议处理函数。</p>

<p><img src="/images/kernel/20221127-11.png" alt="" /></p>

<h4>四层协议（TCP/UDP）</h4>

<p>利用nf_conntrack_proto.c文件中的
<code>
    nf_conntrack_l4proto_register(struct nf_conntrack_l4proto *l4proto)
    和
    nf_conntrack_l4proto_unregister(struct nf_conntrack_l4proto *l4proto)
</code>
在nf_ct_protos[]数组中注册自己的四层协议处理函数。</p>

<p><img src="/images/kernel/20221127-12.png" alt="" /></p>

<h4>处理一个连接的子连接协议</h4>

<p>利用nf_conntrack_helper.c文件中的
<code>
    nf_conntrack_helper_register(struct nf_conntrack_helper *me)
</code>
来注册nf_conntrack_helper结构，</p>

<p>和nf_conntrack_expect.c文件中的
<code>
    nf_ct_expect_related_report(struct nf_conntrack_expect *expect, u32 pid, int report)
</code>
来注册nf_conntrack_expect结构。</p>

<p><img src="/images/kernel/20221127-13.png" alt="" /></p>

<h4>扩展连接跟踪结构（nf_conn）</h4>

<p>利用nf_conntrack_extend.c文件中的
<code>
    nf_ct_extend_register(struct nf_ct_ext_type *type)
    和
    nf_ct_extend_unregister(struct nf_ct_ext_type *type)
</code>
进行扩展，并修改连接跟踪相应代码来利用这部分扩展功能。</p>

<p><img src="/images/kernel/20221127-14.png" alt="" /></p>

<p>了解了上面的数据结构，我们下面来看一下nf_conntrack的执行流程以及如何利用这些数据结构的。首先来看一下nf_conntrack模块加载时的初始化流程。</p>

<p><img src="/images/kernel/20221127-15.png" alt="" /></p>

<h4>nf_conntrack的初始化</h4>

<p>就是初始化上面提到的那些数据结构，它在内核启动时调用nf_conntrack_standalone_init()函数进行初始化的。初始化完成后，构建出如下图所示的结构图，只是不包含下图中与连接有关的信息（nf_conn和nf_conntrack_expect结构）。</p>

<p><img src="/images/kernel/20221127-16.png" alt="" /></p>

<p>上图中有三个HASH桶，ct_hash、expect_hash、helper_hash这三个HASH桶大小在初始化时就已确定，后面不能再更改。其中ct_hash、expect_hash可在加载nf_conntrack.ko模块时通过参数hashsize和expect_hashsize进行设定，而helper_hash不能通过参数修改，它的默认值是page/sizeof(helper_hash)。</p>

<p>下面再来看一个当创建子连接时，各个数据结构之间的关系。</p>

<p><img src="/images/kernel/20221127-17.png" alt="" /></p>

<p>nf_conn和nf_conntrack_expect都有最大个数限制。nf_conn通过全局变量nf_conntrack_max限制，可通过 /proc/sys/net/netfilter/nf_conntrack_max 文件在运行时修改。nf_conntrack_expect通过全局变量nf_ct_expect_max限制，可通过 /proc/sys/net/netfilter/nf_conntrack_expect_max 文件在运行时修改。nf_conntrack_helper没有最大数限制，因为这个是通过注册不同协议的模块添加的，大小取决于动态协议跟踪模块的多少，一般不会很大。</p>

<p>上面两幅数据结构图中，大部分都已介绍过，下面介绍一下netns_ct数据结构，该结构主要用于linux的网络命名空间，表示nf_conntrack在不同的命名空间中都有一套独立的数据信息（这是另一个话题，这里就不再深入讨论了）。</p>

<pre><code>    struct netns_ct {
        atomic_t            count;              /* 当前连接表中连接的个数 */
        unsigned int        expect_count;           /* nf_conntrack_helper创建的期待子连接nf_conntrack_expect项的个数 */
        unsigned int        htable_size;            /* 存储连接（nf_conn）的HASH桶的大小 */
        struct kmem_cache   *nf_conntrack_cachep;       /* 指向用于分配nf_conn结构而建立的高速缓存（slab）对象 */
        struct hlist_nulls_head *hash;              /* 指向存储连接（nf_conn）的HASH桶 */
        struct hlist_head       *expect_hash;           /* 指向存储期待子连接nf_conntrack_expect项的HASH桶 */
        struct hlist_nulls_head unconfirmed;            /* 对于一个链接的第一个包，在init_conntrack()函数中会将该包original方向的tuple结构挂入该链，这是因为在此时还不确定该链接会不会被后续的规则过滤掉，如果被过滤掉就没有必要挂入正式的链接跟踪表。在ipv4_confirm()函数中，会将unconfirmed链中的tuple拆掉，然后再将original方向和reply方向的tuple挂入到正式的链接跟踪表中，即init_net.ct.hash中，这是因为到达ipv4_confirm()函数时，应经在钩子NF_IP_POST_ROUTING处了，已经通过了前面的filter表。 通过cat  /proc/net/nf_conntrack显示连接，是不会显示该链中的连接的。但总的连接个数（net-&gt;ct.count）包含该链中的连接。当注销l3proto、l4proto、helper、nat等资源或在应用层删除所有连接（conntrack -F）时，除了释放confirmed连接（在net-&gt;ct.hash中的连接）的资源，还要释放unconfirmed连接（即在该链中的连接）的资源。*/
        struct hlist_nulls_head dying;              /* 释放连接时，通告DESTROY事件失败的ct被放入该链中，并设置定时器，等待下次通告。 通过cat  /proc/net/nf_conntrack显示连接，是不会显示该链中的连接的。但总的连接个数（net-&gt;ct.count）包含该链中的连接。当注销连接跟踪模块时，同时要清除正再等待被释放的连接（即该链中的连接）*/
        struct ip_conntrack_stat    __percpu *stat;         /* 连接跟踪过程中的一些状态统计，每个CPU一项，目的是为了减少锁 */
        int         sysctl_events;          /* 是否开启连接事件通告功能 */
        unsigned int        sysctl_events_retry_timeout;    /* 通告失败后，重试通告的间隔时间，单位是秒 */
        int         sysctl_acct;            /* 是否开启每个连接数据包统计功能 */
        int         sysctl_checksum;
        unsigned int        sysctl_log_invalid;      /* Log invalid packets */
    #ifdef CONFIG_SYSCTL
        struct ctl_table_header *sysctl_header;
        struct ctl_table_header *acct_sysctl_header;
        struct ctl_table_header *event_sysctl_header;
    #endif
        int         hash_vmalloc;           /* 存储连接（nf_conn）的HASH桶是否是使用vmalloc()进行分配的 */
        int         expect_vmalloc;         /* 存储期待子连接nf_conntrack_expect项的HASH桶是否是使用vmalloc()进行分配的 */
        char            *slabname;          /* 用于分配nf_conn结构而建立的高速缓存（slab）对象的名字 */
    };
</code></pre>

<p>从nf_conntrack的框架来看，它可用于跟踪任何三层和四协议的连接，但目前在三层协议只实现了IPv4和IPv6的连接跟踪，下面我们以IPv4为例，介绍一下该协议是如何利用nf_conntrack框架和netfilter实现连接跟踪的。有关netfilter框架，可参考我的另一个帖子</p>

<p><a href="http://bbs.chinaunix.net/forum.php?mod=viewthread&amp;tid=3749208&amp;fromuid=20171559">linux-2.6.35.6内核netfilter框架</a></p>

<p>首先介绍一下IPv4协议连接跟踪模块的初始化。</p>

<p>Ipv4连接跟踪模块注册了自己的3层协议，和IPv4相关的三个4层协议TCP、UDP、ICMP。注册后的结构图如下图所示：</p>

<p><img src="/images/kernel/20221127-18.png" alt="" /></p>

<p>在netfilter框架中利用
<code>
    nf_register_hook(struct nf_hook_ops *reg)、nf_unregister_hook(struct nf_hook_ops *reg)
</code>
函数注册自己的钩子项，调用nf_conntrack_in()函数来建立相应连接。</p>

<p><img src="/images/kernel/20221127-19.png" alt="" /></p>

<p>这样数据包就会经过ipv4注册的钩子项，并调用nf_conntrack_in()函数建立连接表项，连接表项中的tuple由ipv4注册的3/4层协议处理函数构建。</p>

<p>ipv4_conntrack_in() 挂载在NF_IP_PRE_ROUTING点上。该函数主要功能是创建链接，即创建struct nf_conn结构，同时填充struct nf_conn中的一些必要的信息，例如链接状态、引用计数、helper结构等。</p>

<p>ipv4_confirm() 挂载在NF_IP_POST_ROUTING和NF_IP_LOCAL_IN点上。该函数主要功能是确认一个链接。对于一个新链接，在ipv4_conntrack_in()函数中只是创建了struct nf_conn结构，但并没有将该结构挂载到链接跟踪的Hash表中，因为此时还不能确定该链接是否会被NF_IP_FORWARD点上的钩子函数过滤掉，所以将挂载到Hash表的工作放到了ipv4_confirm()函数中。同时，子链接的helper功能也是在该函数中实现的。</p>

<p>ipv4_conntrack_local() 挂载在NF_IP_LOCAL_OUT点上。该函数功能与ipv4_conntrack_in()函数基本相同，但其用来处理本机主动向外发起的链接。</p>

<p>nf_conntrack_ipv4_compat_init() &ndash;> register_pernet_subsys() &ndash;> ip_conntrack_net_init() 创建/proc文件ip_conntrack和ip_conntrack_expect</p>

<p>如上面所示，IPv4连接跟踪模块已初始化完成，下面我们来看一下它创建连接的流程图。上图中连接的建立主要由三个函数来完成，即ipv4_conntrack_in()，ipv4_confirm()与ipv4_conntrack_local()。其中ipv4_conntrack_in()与ipv4_conntrack_local()都是通过调用函数nf_conntrack_in()来实现的，所以下面我们主要关注nf_conntrack_in()与ipv4_confirm()这两个函数。nf_conntrack_in()函数主要完成创建链接、添加链接的扩展结构(例如helper, acct结构)、设置链接状态等。ipv4_confirm()函数主要负责确认链接(即将链接挂入到正式的链接表中)、执行helper函数、启动链接超时定时器等。另外还有一个定时器函数death_by_timeout(), 该函数负责链接到期时删除该链接。</p>

<p>nf_conntrack_in()函数流程图</p>

<p><img src="/images/kernel/20221127-20.png" alt="" /></p>

<p>ipv4_confirm()函数流程图</p>

<p><img src="/images/kernel/20221127-21.png" alt="" /></p>

<p>death_by_timeout()函数流程图</p>

<p><img src="/images/kernel/20221127-22.png" alt="" /></p>

<p>上图中有一点需要说明，由于skb会引用nf_conn，同时会增加它的引用计数，所以当skb被释放时，也要释放nf_conn的引用计数，并且在nf_conn引用计数为0时，要释放全部资源。</p>

<p>当数据包经过nf_conntrack_in()和ipv4_confirm()函数处理流程后，就会建立起3楼第二幅结构图所示的连接nf_conn。同时这两个函数已经包含了子连接的处理流程，即流程图中help和exp的处理。子连接建立后的结构图如3楼第三幅结构图，主链接与子连接通过helper和expect关联起来。</p>

<p>连接跟踪到此就介绍完了，下面介绍IPv4基于nf_conntrack框架适合实现NAT转换的。先介绍IPv4-NAT初始化的资源，然后处理流程。</p>

<h2>IPv4-NAT连接跟踪相关部分通过函数nf_nat_init()初始化</h2>

<p>调用nf_ct_extend_register() 注册一个连接跟踪的扩展功能。</p>

<p><img src="/images/kernel/20221127-23.png" alt="" /></p>

<p>调用register_pernet_subsys() &ndash;> nf_nat_net_init() 创建net->ipv4.nat_bysource的HASH表，大小等于net->ct.htable_size。</p>

<p>初始化nf_nat_protos[]数组，为TCP、UDP、ICMP协议指定专用处理结构，其它协议都指向默认处理结构。</p>

<p><img src="/images/kernel/20221127-24.png" alt="" /></p>

<p>为nf_conntrack_untracked连接设置IPS_NAT_DONE_MASK标志。</p>

<p>将NAT模块的全局变量l3proto指向IPV4协议的nf_conntrack_l3proto结构。</p>

<p>设置全局指针nf_nat_seq_adjust_hook指向nf_nat_seq_adjust()函数。</p>

<p>设置全局指针nfnetlink_parse_nat_setup_hook指向nfnetlink_parse_nat_setup()函数。</p>

<p>设置全局指针nf_ct_nat_offset指向nf_nat_get_offset()函数。</p>

<h2>IPv4-NAT功能的iptables部分通过函数nf_nat_standalone_init()初始化</h2>

<p>调用nf_nat_rule_init() &ndash;> nf_nat_rule_net_init()在iptables中注册一个NAT表（通过ipt_register_table()函数，参考另一个帖子iptables）</p>

<p>调用 nf_nat_rule_init() 注册SNAT target和DNAT target（通过xt_register_target()函数）</p>

<p><img src="/images/kernel/20221127-25.png" alt="" /></p>

<p>调用nf_register_hooks() 挂载NAT的HOOK函数，橙色部分为NAT挂载的HOOK函数（参考另一个帖子netfilter）</p>

<p><img src="/images/kernel/20221127-26.png" alt="" /></p>

<p>根据上面介绍，可以看到IPv4-NAT的主要是通过nf_nat_fn()钩子函数处理的，下面我就来看看nf_nat_fn()函数的处理流程。</p>

<p><img src="/images/kernel/20221127-27.png" alt="" /></p>

<p>针对上图中的nf_nat_setup_info()函数进一步描述</p>

<p><img src="/images/kernel/20221127-28.png" alt="" /></p>

<h2>下面对NAT转换算法中重要部分做一些文字说明</h2>

<p>每个ct在第一个包就会做好snat与dnat, nat的信息全放在reply tuple中，orig tuple不会被改变。一旦第一个包建立好nat信息后，后续再也不会修改tuple内容了。</p>

<p>orig tuple中的地址信息与reply tuple中的地址信息就是原始数据包的信息。例如对A->B数据包同时做snat与dnat，PREROUTING处B被dnat到D，POSTROUTING处A被snat到C。则ct的内容是:  A->B | D->C,  A->B说明了orig方向上数据包刚到达墙时的地址内容，D->C说明reply方向上数据包刚到达墙时的地址内容。</p>

<p>在代码中有很多!dir操作，原理是: 当为了反向的数据包做事情的时候就取反向tuple的数据，这样才能保证NAT后的tuple信息被正确使用。</p>

<p>bysource链中链接了所有CT（做过NAT和未做过NAT），通过ct->nat->bysource，HASH值的计算使用的是CT的orig tuple。其作用是，当为一个新连接做SNAT，需要得到地址映射时，首先对该链进行查找，查找此源IP、协议和端口号是否已经做过了映射。如果做过的话，就需要在SNAT转换时，映射为相同的源IP和端口号。为什么要这么做呢？因为对于UDP来说，有些协议可能会用相同端口和同一主机不同的端口（或不同的主机）进行通信。此时，由于目的地不同，原来已有的映射不可使用，需要一个新的连接。但为了保证通信的的正确性，此时，就要映射为相同的源IP和端口号。其实就是为NAT的打洞服务的。所以bysource就是以源IP、协议和端口号为hash值的一个表，这样在做snat时保证相同的ip+port影射到相同的ip+port。</p>

<p>IP_NAT_RANGE_PROTO_RANDOM指的是做nat时，当计算端口时，如果没有此random标志，则会先使用原始得tuple中的端口试一下看是否可用，如果可用就使用该原始端口作为nat后的端口， 即尽量保证转换后的端口与转换前的端口保持一致。如果不可用，再根据nat的端口算法计算出一个端口。 如果有此标记，则直接根据端口算法计算出端口。</p>

<p>第一个包之后，ct的两个方向的tuple内容就固定了，所有的nat操作都必须在第一个包就完成。所以会有daddr = &amp;ct->tuplehash[!dir].tuple.dst.u3;这样的操作。</p>

<p>IPS_SRC_NAT与IPS_DST_NAT，如果被设置，表示经过了NAT，并且ct中的tuple被做过SNAT或DNAT。</p>

<p>数据包永远都是在PREROUTING链做目的地址和目的端口转换，在POSTROUTING链做原地址和原端口转换。是否要做NAT转换则要根数据包方向（dir）和NAT标志（IPS_SRC_NAT或IPS_DST_NAT）来判断。</p>

<p>在PREROUTING链上&mdash;>数据包是original方向、并且连接上设置IPS_DST_NAT标志，或数据包是reply方向、并且连接上设置IPS_SRC_NAT标志，则做DNAT转换。</p>

<p>在POSTROUTING链上&mdash;>数据包是original方向、并且连接上设置IPS_SRC_NAT标志，或数据包是reply方向、并且连接上设置IPS_DST_NAT标志，则做SNAT转换。</p>

<p>IPS_DST_NAT_DONE_BIT与IPS_SRC_NAT_DONE_BIT，表示该ct进入过NAT模块，已经进行了源或者目的NAT判断，但并不表示ct中的tuple被修改过。</p>

<p>源目的nat都是在第一个包就判断完成的，假设先添加了snat策略，第一个包通过，这时又添加了dnat策略, 第二个包到来时是不会匹配dnat策略的 。</p>

<p>对于一个ct，nf_nat_setup_info函数最多只能进入2次，第一次DNAT，第二次SNAT。在nf_nat_follow_master函数中，第一次SNAT，第二次DNAT。</p>

<p>下面介绍有子连接的NAT实现。有两个关键点：1.主链接能正确的构建出NAT后的expect来识别子连接。2.能够修改主链接数据通道的信息为NAT后的信息。这两点都在动态协议的help中完成，下面我们来看一下它的流程图：</p>

<p><img src="/images/kernel/20221127-29.png" alt="" /></p>

<h2>下面针对有无子连接的NAT做一下对比</h2>

<h4>无子连接的NAT</h4>

<p>一个ct用于跟踪一个连接的双方向数据，ct->orig_tuple用于跟踪初始方向数据，ct->reply_tuple用于跟踪应答方向数据。当根据初始方向数据构建ct->orig_tuple时，同时要构建出ct->reply_tuple，用于识别同一连接上应答方向数据。</p>

<p>如果初始方向的数据在通过防火墙后被做了NAT转换，为识别出NAT数据的应答数据包，则对ct->reply_tuple也要做NAT转换。同时ct上做好相应NAT标记。</p>

<p>因此，上面的信息在初始方向第一个数据包通过后，就要求全部建立好，并且不再改变。</p>

<p>一个连接上不同方向的数据，都有相对应的tuple（orig_tuple和reply_tuple），所以该连接后续数据都将被识别出来。如果ct上有NAT标记，则根据要去往方向（即另一个方向）的tuple对数据做NAT转换。所以会有ct->tuplehash[!dir].tuple这样的操作。</p>

<h4>有子连接的NAT</h4>

<p>子连接是由主连接构建的expect项识别出来的。</p>

<p>help用于构建expect项，它期待哪个方向的连接，则用那个方向的tuple和数据包中数据通道信息构建expect项。例如期待和当前数据包相反方向的连接，则用相反方向的tuple中的信息（ct->tuplehash[!dir].tuple）。调用help时，NAT转换都已完成（tuple中都包含有正确的识别各自方向的信息），所以这时所使用的信息都是正确和所期望的信息。</p>

<p>如果子连接还可能有子连接，则构建expect项时，初始化一个helper结构，并赋值给expect->helper指针。</p>

<p>如果该连接已被做了NAT转换，则对数据包中数据通道信息也要做NAT转换</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Linux网络栈之队列]]></title>
    <link href="http://abcdxyzk.github.io/blog/2021/06/08/net-queue/"/>
    <updated>2021-06-08T16:55:00+08:00</updated>
    <id>http://abcdxyzk.github.io/blog/2021/06/08/net-queue</id>
    <content type="html"><![CDATA[<p><a href="https://zhensheng.im/2017/08/11/%e7%bf%bb%e8%af%91linux%e7%bd%91%e7%bb%9c%e6%a0%88%e4%b9%8b%e9%98%9f%e5%88%97.meow">https://zhensheng.im/2017/08/11/%e7%bf%bb%e8%af%91linux%e7%bd%91%e7%bb%9c%e6%a0%88%e4%b9%8b%e9%98%9f%e5%88%97.meow</a></p>

<p>数据包队列是任何一个网络栈的核心组件，数据包队列实现了异步模块之间的通讯，提升了网络性能，并且拥有影响延迟的副作用。本文的目标，是解释Linux的网络栈中IP数据包在何处排队，新的延迟降低技术如BQL是多么的有趣，以及如何控制缓冲区以降低延迟。</p>

<p>下面这张图片将会贯穿全文，其多个修改版本将会用来解释一些特别的概念。</p>

<p><img src="/images/kernel/20210608-5.png" alt="" /></p>

<p>图片一 – Simplified high level overview of the queues on the transmit path of the Linux 网络栈</p>

<h2>驱动队列(Driver Queue，又名环形缓冲）</h2>

<p>在内核的IP stack和网络接口控制器（NIC）之间，存在一个驱动队列。这个队列典型地以一个先进先出的环形缓冲区实现 —— 即一个固定大小的缓冲区。驱动队列并不附带数据包数据，而是持有指向内核中名为socket kernel buffers(SKBs)的结构体的描述符，SKBs持有数据包的数据并且在整个内核中使用。</p>

<p><img src="/images/kernel/20210608-6.png" alt="" /></p>

<p>图片 2 – Partially full driver queue with descriptors pointing to SKBs</p>

<p>驱动队列的输入来源是一个为所有数据包排队的IP stack，这些数据包可能是本地生成，或者在一个路由器上，由一个NIC接收然后选路从另一个NIC发出。数据包从IP stack入队到驱动队列后，将会被驱动程序执行出队操作，然后通过数据总线进行传输。</p>

<p>驱动队列之所以存在，是为了保证系统无论在任何需要传输数据， NIC都能立即传输。换言之，驱动队列从硬件上给予了IP stack一个异步数据排队的地方。一个可选的方式是当NIC可以传输数据时，主动向IP stack索取数据，但这种设计模式下，无法实时对NIC响应，浪费了珍贵的传输机会，损失了网络吞吐量。另一个与此相反的方法是IP stack创建一个数据包后，需要同步等待NIC，直到NIC可以发送数据包，这也不是一个好的设计模式，因为在同步等待的过程中IP stack无法执行其它工作。</p>

<h2>巨型数据包</h2>

<p>绝大多数的NIC都拥有一个固定的最大传输单元（MTU），意思是物理媒介可以传输的最大帧。以太网默认的MTU是1,500字节，但一些以太网络支持上限9,000字节的巨型帧(Jumbo Frames)。在IP 网络栈中，MTU描述了一个可被传输的数据包大小上限。例如，一个应用程序通过TCP socket发送了2,000字节的数据，IP stack就需要把这份数据拆分成数个数据包，以保持单个数据包的小于或等于MTU(1,500)。传输大量数据时，小的MTU将会产生更多分包。</p>

<p>为了避免大量数据包排队，Linux内核实现了数个优化：TCP segmentation offload (TSO), UDP fragmentation offload (UFO) 和 generic segmentation offload (GSO)，这些优化机制允许IP stack创建大于出口NIC MTU的数据包。以IPv4为例，可以创建上限为65,536字节的数据包，并且可以入队到驱动队列。在TSO和UFO中，NIC在硬件上实现并负责拆分大数据包，以适合在物理链路上传输。对于没有TSO和UFO支持的NIC，GSO则在软件上实现同样的功能。</p>

<p>前文提到，驱动队列只有固定容量，只能存放固定数量的描述符，由于TSO，UFO和GSO的特性，使得大型的数据包可以加入到驱动队列当中，从而间接地增加了队列的容量。图三与图二的比较，解释了这个概念。</p>

<p><img src="/images/kernel/20210608-7.png" alt="" /></p>

<p>图片 3 – Large packets can be sent to the NIC when TSO, UFO or GSO are enabled. This can greatly increase the number of bytes in the driver queue.</p>

<p>虽然本文的其余部分重点介绍传输路径，但值得注意的是Linux也有工作方式像TSO，UFO和GSO的接收端优化。这些优化的目标也是减少每一个数据包的开销。特别地，generic receive offload (GRO)允许NIC驱动把接收到的数据包组合成一个大型数据包，然后加入IP stack。在转发数据包的时候，为了维护端对端IP数据包的特性，GRO会重新组合接收到的数据包。然而，这只是单端效果，当大型数据包在转发方处拆分时，将会出现多个数据包一次性入队的情况，这种数据包"微型突发"会给网络延迟带来负面影响。</p>

<h2>饥饿与延迟</h2>

<p>先不讨论必要性与优点，在IP stack和硬件之间的队列描述了两个问题：饥饿与延迟。</p>

<p>如果NIC驱动程序要处理队列，此时队列为空，NIC将会失去一个传输数据的机会，导致系统的生产量降低。这种情况定义为饥饿。需要注意：当操作系统没有任何数据需要传输时，队列为空的话，并不归类为饥饿，而是正常。为了避免饥饿，IP stack在填充驱动队列的同时，NIC驱动程序也要进行出队操作。糟糕的是，队列填满或为空的事件持续的时间会随着系统和外部的情况而变化。例如，在一个繁忙的操作系统上，IP stack很少有机会往驱动队列中入队数据包，这样有很大的几率出现驱动队列为空的情况。拥有一个大容量的驱动队列缓冲区，有利于减少饥饿的几率，提高网络吞吐量。</p>

<p>虽然一个大的队列有利于增加吞吐量，但缺点也很明显：提高了延迟。</p>

<p><img src="/images/kernel/20210608-8.png" alt="" /></p>

<p>图片 4 – Interactive packet (yellow) behind bulk flow packets (blue)</p>

<p>图片4展示了驱动队列几乎被单个高流量（蓝色）的TCP段填满。队列中最后一个数据包来自VoIP或者游戏（黄色）。交互式应用，例如VoIP或游戏会在固定的间隔发送小数据包，占用大量带宽的数据传输会使用高数据包传输速率传输大量数据包，高速率的数据包传输将会在交互式数据包之间插入大量数据包，从而导致这些交互式数据包延迟传输。为了进一步解释这种情况，假设有如下场景：</p>

<p>  一个网络接口拥有5 Mbit/sec(或5,000,000 bit/sec)的传输能力</p>

<p>  每一个大流量的数据包都是1,500 bytes或12,000 bits。</p>

<p>  每一个交互式数据包都是500 bytes。</p>

<p>  驱动队列的长度为128。</p>

<p>  有127个大流量数据包，还有1个交互式数据包排在队列末尾。</p>

<p>在上述情况下，发送127个大流量的数据包，需要(127 * 12,000) / 5,000,000 = 0.304 秒(以ping的方式来看，延迟值为304毫秒)。如此高的延迟，对于交互式程序来说是无法接受的，然而这还没计算往返时间。前文提到，通过TSO，UFO，GSO技术，大型数据包还可以在队列中排队，这将导致延迟问题更严重。</p>

<p>大的延迟，一般由过大、疏于管理的缓冲区造成，如Bufferbloat。更多关于此现象的细节，可以查阅控制队列延迟（Controlling Queue Delay），以及Bufferbloat项目。</p>

<p>如上所述，为驱动队列选择一个合适的容量是一个Goldilocks问题 – 这个值不能太小，否则损失吞吐量，也不能太大，否则过增延迟。</p>

<h2>字节级队列限制（Byte Queue Limits (BQL)）</h2>

<p>Byte Queue Limits (BQL)是一个在Linux Kernel 3.3.0加入的新特性，以自动解决驱动队列容量问题。BQL通过添加一个协议，计算出的当前情况下避免饥饿的最小数据包缓冲区大小，以决定是否允许继续向驱动队列中入队数据包。根据前文，排队的数据包越少，数据包排队的最大发送延迟就越低。</p>

<p>需要注意，驱动队列的容量并不能被BQL修改，BQL做的只是计算出一个限制值，表示当时有多少的数据可以被排队。任何超过此限制的数据，是等待还是被丢弃，会根据协议而定。</p>

<p>BQL机制在以下两种事件发生时将会触发：数据包入队，数据包传输完成。一个简化的BQL算法版本概括如下IMIT为BQL根据当前情况计算出的限制值。
<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
<span class='line-number'>55</span>
<span class='line-number'>56</span>
<span class='line-number'>57</span>
<span class='line-number'>58</span>
<span class='line-number'>59</span>
<span class='line-number'>60</span>
<span class='line-number'>61</span>
<span class='line-number'>62</span>
<span class='line-number'>63</span>
<span class='line-number'>64</span>
<span class='line-number'>65</span>
<span class='line-number'>66</span>
<span class='line-number'>67</span>
<span class='line-number'>68</span>
<span class='line-number'>69</span>
<span class='line-number'>70</span>
<span class='line-number'>71</span>
<span class='line-number'>72</span>
<span class='line-number'>73</span>
<span class='line-number'>74</span>
<span class='line-number'>75</span>
<span class='line-number'>76</span>
<span class='line-number'>77</span>
<span class='line-number'>78</span>
<span class='line-number'>79</span>
<span class='line-number'>80</span>
<span class='line-number'>81</span>
<span class='line-number'>82</span>
<span class='line-number'>83</span>
<span class='line-number'>84</span>
<span class='line-number'>85</span>
<span class='line-number'>86</span>
<span class='line-number'>87</span>
<span class='line-number'>88</span>
<span class='line-number'>89</span>
<span class='line-number'>90</span>
<span class='line-number'>91</span>
<span class='line-number'>92</span>
<span class='line-number'>93</span>
<span class='line-number'>94</span>
<span class='line-number'>95</span>
<span class='line-number'>96</span>
<span class='line-number'>97</span>
<span class='line-number'>98</span>
<span class='line-number'>99</span>
<span class='line-number'>100</span>
<span class='line-number'>101</span>
<span class='line-number'>102</span>
<span class='line-number'>103</span>
<span class='line-number'>104</span>
<span class='line-number'>105</span>
<span class='line-number'>106</span>
<span class='line-number'>107</span>
<span class='line-number'>108</span>
<span class='line-number'>109</span>
<span class='line-number'>110</span>
<span class='line-number'>111</span>
<span class='line-number'>112</span>
<span class='line-number'>113</span>
<span class='line-number'>114</span>
<span class='line-number'>115</span>
<span class='line-number'>116</span>
<span class='line-number'>117</span>
<span class='line-number'>118</span>
<span class='line-number'>119</span>
<span class='line-number'>120</span>
<span class='line-number'>121</span>
<span class='line-number'>122</span>
<span class='line-number'>123</span>
<span class='line-number'>124</span>
<span class='line-number'>125</span>
<span class='line-number'>126</span>
<span class='line-number'>127</span>
<span class='line-number'>128</span>
<span class='line-number'>129</span>
<span class='line-number'>130</span>
<span class='line-number'>131</span>
<span class='line-number'>132</span>
<span class='line-number'>133</span>
<span class='line-number'>134</span>
<span class='line-number'>135</span>
<span class='line-number'>136</span>
<span class='line-number'>137</span>
<span class='line-number'>138</span>
<span class='line-number'>139</span>
<span class='line-number'>140</span>
<span class='line-number'>141</span>
<span class='line-number'>142</span>
<span class='line-number'>143</span>
<span class='line-number'>144</span>
<span class='line-number'>145</span>
<span class='line-number'>146</span>
<span class='line-number'>147</span>
<span class='line-number'>148</span>
<span class='line-number'>149</span>
<span class='line-number'>150</span>
<span class='line-number'>151</span>
<span class='line-number'>152</span>
<span class='line-number'>153</span>
<span class='line-number'>154</span>
<span class='line-number'>155</span>
<span class='line-number'>156</span>
<span class='line-number'>157</span>
<span class='line-number'>158</span>
<span class='line-number'>159</span>
<span class='line-number'>160</span>
<span class='line-number'>161</span>
<span class='line-number'>162</span>
<span class='line-number'>163</span>
<span class='line-number'>164</span>
<span class='line-number'>165</span>
<span class='line-number'>166</span>
<span class='line-number'>167</span>
<span class='line-number'>168</span>
<span class='line-number'>169</span>
<span class='line-number'>170</span>
<span class='line-number'>171</span>
<span class='line-number'>172</span>
<span class='line-number'>173</span>
<span class='line-number'>174</span>
<span class='line-number'>175</span>
<span class='line-number'>176</span>
<span class='line-number'>177</span>
<span class='line-number'>178</span>
<span class='line-number'>179</span>
<span class='line-number'>180</span>
<span class='line-number'>181</span>
<span class='line-number'>182</span>
<span class='line-number'>183</span>
<span class='line-number'>184</span>
<span class='line-number'>185</span>
<span class='line-number'>186</span>
<span class='line-number'>187</span>
<span class='line-number'>188</span>
<span class='line-number'>189</span>
<span class='line-number'>190</span>
<span class='line-number'>191</span>
<span class='line-number'>192</span>
<span class='line-number'>193</span>
<span class='line-number'>194</span>
<span class='line-number'>195</span>
<span class='line-number'>196</span>
<span class='line-number'>197</span>
<span class='line-number'>198</span>
<span class='line-number'>199</span>
<span class='line-number'>200</span>
<span class='line-number'>201</span>
<span class='line-number'>202</span>
<span class='line-number'>203</span>
<span class='line-number'>204</span>
<span class='line-number'>205</span>
<span class='line-number'>206</span>
<span class='line-number'>207</span>
<span class='line-number'>208</span>
<span class='line-number'>209</span>
<span class='line-number'>210</span>
<span class='line-number'>211</span>
<span class='line-number'>212</span>
<span class='line-number'>213</span>
<span class='line-number'>214</span>
<span class='line-number'>215</span>
<span class='line-number'>216</span>
<span class='line-number'>217</span>
<span class='line-number'>218</span>
<span class='line-number'>219</span>
<span class='line-number'>220</span>
<span class='line-number'>221</span>
<span class='line-number'>222</span>
<span class='line-number'>223</span>
<span class='line-number'>224</span>
<span class='line-number'>225</span>
<span class='line-number'>226</span>
<span class='line-number'>227</span>
<span class='line-number'>228</span>
<span class='line-number'>229</span>
<span class='line-number'>230</span>
<span class='line-number'>231</span>
<span class='line-number'>232</span>
<span class='line-number'>233</span>
<span class='line-number'>234</span>
<span class='line-number'>235</span>
<span class='line-number'>236</span>
<span class='line-number'>237</span>
<span class='line-number'>238</span>
<span class='line-number'>239</span>
<span class='line-number'>240</span>
<span class='line-number'>241</span>
<span class='line-number'>242</span>
<span class='line-number'>243</span>
<span class='line-number'>244</span>
<span class='line-number'>245</span>
<span class='line-number'>246</span>
<span class='line-number'>247</span>
<span class='line-number'>248</span>
<span class='line-number'>249</span>
<span class='line-number'>250</span>
<span class='line-number'>251</span>
<span class='line-number'>252</span>
<span class='line-number'>253</span>
<span class='line-number'>254</span>
<span class='line-number'>255</span>
<span class='line-number'>256</span>
<span class='line-number'>257</span>
<span class='line-number'>258</span>
<span class='line-number'>259</span>
<span class='line-number'>260</span>
<span class='line-number'>261</span>
<span class='line-number'>262</span>
<span class='line-number'>263</span>
<span class='line-number'>264</span>
<span class='line-number'>265</span>
<span class='line-number'>266</span>
<span class='line-number'>267</span>
<span class='line-number'>268</span>
<span class='line-number'>269</span>
<span class='line-number'>270</span>
<span class='line-number'>271</span>
<span class='line-number'>272</span>
<span class='line-number'>273</span>
<span class='line-number'>274</span>
<span class='line-number'>275</span>
<span class='line-number'>276</span>
<span class='line-number'>277</span>
<span class='line-number'>278</span>
<span class='line-number'>279</span>
<span class='line-number'>280</span>
<span class='line-number'>281</span>
<span class='line-number'>282</span>
<span class='line-number'>283</span>
<span class='line-number'>284</span>
<span class='line-number'>285</span>
<span class='line-number'>286</span>
<span class='line-number'>287</span>
<span class='line-number'>288</span>
<span class='line-number'>289</span>
<span class='line-number'>290</span>
<span class='line-number'>291</span>
<span class='line-number'>292</span>
<span class='line-number'>293</span>
<span class='line-number'>294</span>
<span class='line-number'>295</span>
<span class='line-number'>296</span>
<span class='line-number'>297</span>
<span class='line-number'>298</span>
<span class='line-number'>299</span>
<span class='line-number'>300</span>
<span class='line-number'>301</span>
<span class='line-number'>302</span>
<span class='line-number'>303</span>
<span class='line-number'>304</span>
<span class='line-number'>305</span>
<span class='line-number'>306</span>
<span class='line-number'>307</span>
<span class='line-number'>308</span>
<span class='line-number'>309</span>
<span class='line-number'>310</span>
<span class='line-number'>311</span>
<span class='line-number'>312</span>
<span class='line-number'>313</span>
<span class='line-number'>314</span>
<span class='line-number'>315</span>
<span class='line-number'>316</span>
<span class='line-number'>317</span>
<span class='line-number'>318</span>
<span class='line-number'>319</span>
<span class='line-number'>320</span>
<span class='line-number'>321</span>
<span class='line-number'>322</span>
<span class='line-number'>323</span>
<span class='line-number'>324</span>
<span class='line-number'>325</span>
<span class='line-number'>326</span>
<span class='line-number'>327</span>
<span class='line-number'>328</span>
<span class='line-number'>329</span>
<span class='line-number'>330</span>
<span class='line-number'>331</span>
<span class='line-number'>332</span>
<span class='line-number'>333</span>
<span class='line-number'>334</span>
<span class='line-number'>335</span>
<span class='line-number'>336</span>
<span class='line-number'>337</span>
<span class='line-number'>338</span>
<span class='line-number'>339</span>
<span class='line-number'>340</span>
<span class='line-number'>341</span>
<span class='line-number'>342</span>
<span class='line-number'>343</span>
<span class='line-number'>344</span>
<span class='line-number'>345</span>
<span class='line-number'>346</span>
<span class='line-number'>347</span>
<span class='line-number'>348</span>
<span class='line-number'>349</span>
<span class='line-number'>350</span>
<span class='line-number'>351</span>
<span class='line-number'>352</span>
<span class='line-number'>353</span>
<span class='line-number'>354</span>
<span class='line-number'>355</span>
<span class='line-number'>356</span>
<span class='line-number'>357</span>
<span class='line-number'>358</span>
<span class='line-number'>359</span>
<span class='line-number'>360</span>
<span class='line-number'>361</span>
<span class='line-number'>362</span>
<span class='line-number'>363</span>
<span class='line-number'>364</span>
<span class='line-number'>365</span>
<span class='line-number'>366</span>
<span class='line-number'>367</span>
<span class='line-number'>368</span>
<span class='line-number'>369</span>
<span class='line-number'>370</span>
<span class='line-number'>371</span>
<span class='line-number'>372</span>
<span class='line-number'>373</span>
<span class='line-number'>374</span>
<span class='line-number'>375</span>
<span class='line-number'>376</span>
<span class='line-number'>377</span>
<span class='line-number'>378</span>
<span class='line-number'>379</span>
<span class='line-number'>380</span>
<span class='line-number'>381</span>
<span class='line-number'>382</span>
<span class='line-number'>383</span>
<span class='line-number'>384</span>
<span class='line-number'>385</span>
<span class='line-number'>386</span>
<span class='line-number'>387</span>
<span class='line-number'>388</span>
<span class='line-number'>389</span>
<span class='line-number'>390</span>
<span class='line-number'>391</span>
<span class='line-number'>392</span>
<span class='line-number'>393</span>
<span class='line-number'>394</span>
<span class='line-number'>395</span>
<span class='line-number'>396</span>
<span class='line-number'>397</span>
<span class='line-number'>398</span>
<span class='line-number'>399</span>
<span class='line-number'>400</span>
<span class='line-number'>401</span>
<span class='line-number'>402</span>
<span class='line-number'>403</span>
<span class='line-number'>404</span>
<span class='line-number'>405</span>
<span class='line-number'>406</span>
<span class='line-number'>407</span>
<span class='line-number'>408</span>
<span class='line-number'>409</span>
<span class='line-number'>410</span>
<span class='line-number'>411</span>
<span class='line-number'>412</span>
<span class='line-number'>413</span>
<span class='line-number'>414</span>
<span class='line-number'>415</span>
<span class='line-number'>416</span>
<span class='line-number'>417</span>
<span class='line-number'>418</span>
<span class='line-number'>419</span>
<span class='line-number'>420</span>
<span class='line-number'>421</span>
<span class='line-number'>422</span>
<span class='line-number'>423</span>
<span class='line-number'>424</span>
<span class='line-number'>425</span>
<span class='line-number'>426</span>
<span class='line-number'>427</span>
<span class='line-number'>428</span>
<span class='line-number'>429</span>
<span class='line-number'>430</span>
<span class='line-number'>431</span>
<span class='line-number'>432</span>
<span class='line-number'>433</span>
<span class='line-number'>434</span>
<span class='line-number'>435</span>
<span class='line-number'>436</span>
<span class='line-number'>437</span>
<span class='line-number'>438</span>
<span class='line-number'>439</span>
<span class='line-number'>440</span>
<span class='line-number'>441</span>
<span class='line-number'>442</span>
<span class='line-number'>443</span>
<span class='line-number'>444</span>
<span class='line-number'>445</span>
<span class='line-number'>446</span>
<span class='line-number'>447</span>
<span class='line-number'>448</span>
<span class='line-number'>449</span>
<span class='line-number'>450</span>
<span class='line-number'>451</span>
<span class='line-number'>452</span>
<span class='line-number'>453</span>
<span class='line-number'>454</span>
<span class='line-number'>455</span>
<span class='line-number'>456</span>
<span class='line-number'>457</span>
<span class='line-number'>458</span>
<span class='line-number'>459</span>
<span class='line-number'>460</span>
<span class='line-number'>461</span>
<span class='line-number'>462</span>
<span class='line-number'>463</span>
<span class='line-number'>464</span>
<span class='line-number'>465</span>
<span class='line-number'>466</span>
<span class='line-number'>467</span>
<span class='line-number'>468</span>
<span class='line-number'>469</span>
<span class='line-number'>470</span>
<span class='line-number'>471</span>
<span class='line-number'>472</span>
<span class='line-number'>473</span>
<span class='line-number'>474</span>
<span class='line-number'>475</span>
<span class='line-number'>476</span>
<span class='line-number'>477</span>
<span class='line-number'>478</span>
<span class='line-number'>479</span>
<span class='line-number'>480</span>
<span class='line-number'>481</span>
<span class='line-number'>482</span>
<span class='line-number'>483</span>
<span class='line-number'>484</span>
<span class='line-number'>485</span>
<span class='line-number'>486</span>
<span class='line-number'>487</span>
<span class='line-number'>488</span>
<span class='line-number'>489</span>
<span class='line-number'>490</span>
<span class='line-number'>491</span>
<span class='line-number'>492</span>
<span class='line-number'>493</span>
<span class='line-number'>494</span>
<span class='line-number'>495</span>
<span class='line-number'>496</span>
<span class='line-number'>497</span>
<span class='line-number'>498</span>
<span class='line-number'>499</span>
<span class='line-number'>500</span>
<span class='line-number'>501</span>
<span class='line-number'>502</span>
<span class='line-number'>503</span>
<span class='line-number'>504</span>
<span class='line-number'>505</span>
<span class='line-number'>506</span>
<span class='line-number'>507</span>
<span class='line-number'>508</span>
<span class='line-number'>509</span>
<span class='line-number'>510</span>
<span class='line-number'>511</span>
<span class='line-number'>512</span>
<span class='line-number'>513</span>
<span class='line-number'>514</span>
<span class='line-number'>515</span>
<span class='line-number'>516</span>
<span class='line-number'>517</span>
<span class='line-number'>518</span>
<span class='line-number'>519</span>
<span class='line-number'>520</span>
<span class='line-number'>521</span>
<span class='line-number'>522</span>
<span class='line-number'>523</span>
<span class='line-number'>524</span>
<span class='line-number'>525</span>
<span class='line-number'>526</span>
<span class='line-number'>527</span>
<span class='line-number'>528</span>
<span class='line-number'>529</span>
<span class='line-number'>530</span>
<span class='line-number'>531</span>
<span class='line-number'>532</span>
<span class='line-number'>533</span>
<span class='line-number'>534</span>
<span class='line-number'>535</span>
<span class='line-number'>536</span>
<span class='line-number'>537</span>
<span class='line-number'>538</span>
<span class='line-number'>539</span>
<span class='line-number'>540</span>
<span class='line-number'>541</span>
<span class='line-number'>542</span>
<span class='line-number'>543</span>
<span class='line-number'>544</span>
<span class='line-number'>545</span>
<span class='line-number'>546</span>
<span class='line-number'>547</span>
<span class='line-number'>548</span>
<span class='line-number'>549</span>
<span class='line-number'>550</span>
<span class='line-number'>551</span>
<span class='line-number'>552</span>
<span class='line-number'>553</span>
<span class='line-number'>554</span>
<span class='line-number'>555</span>
<span class='line-number'>556</span>
<span class='line-number'>557</span>
<span class='line-number'>558</span>
<span class='line-number'>559</span>
<span class='line-number'>560</span>
<span class='line-number'>561</span>
<span class='line-number'>562</span>
<span class='line-number'>563</span>
<span class='line-number'>564</span>
<span class='line-number'>565</span>
<span class='line-number'>566</span>
<span class='line-number'>567</span>
<span class='line-number'>568</span>
<span class='line-number'>569</span>
<span class='line-number'>570</span>
<span class='line-number'>571</span>
<span class='line-number'>572</span>
<span class='line-number'>573</span>
<span class='line-number'>574</span>
<span class='line-number'>575</span>
<span class='line-number'>576</span>
<span class='line-number'>577</span>
<span class='line-number'>578</span>
<span class='line-number'>579</span>
<span class='line-number'>580</span>
<span class='line-number'>581</span>
<span class='line-number'>582</span>
<span class='line-number'>583</span>
<span class='line-number'>584</span>
<span class='line-number'>585</span>
<span class='line-number'>586</span>
<span class='line-number'>587</span>
<span class='line-number'>588</span>
<span class='line-number'>589</span>
<span class='line-number'>590</span>
<span class='line-number'>591</span>
<span class='line-number'>592</span>
<span class='line-number'>593</span>
<span class='line-number'>594</span>
<span class='line-number'>595</span>
<span class='line-number'>596</span>
<span class='line-number'>597</span>
<span class='line-number'>598</span>
<span class='line-number'>599</span>
<span class='line-number'>600</span>
<span class='line-number'>601</span>
<span class='line-number'>602</span>
<span class='line-number'>603</span>
<span class='line-number'>604</span>
<span class='line-number'>605</span>
<span class='line-number'>606</span>
<span class='line-number'>607</span>
<span class='line-number'>608</span>
<span class='line-number'>609</span>
<span class='line-number'>610</span>
<span class='line-number'>611</span>
<span class='line-number'>612</span>
<span class='line-number'>613</span>
<span class='line-number'>614</span>
<span class='line-number'>615</span>
<span class='line-number'>616</span>
<span class='line-number'>617</span>
<span class='line-number'>618</span>
<span class='line-number'>619</span>
<span class='line-number'>620</span>
<span class='line-number'>621</span>
<span class='line-number'>622</span>
<span class='line-number'>623</span>
<span class='line-number'>624</span>
<span class='line-number'>625</span>
<span class='line-number'>626</span>
<span class='line-number'>627</span>
<span class='line-number'>628</span>
<span class='line-number'>629</span>
<span class='line-number'>630</span>
<span class='line-number'>631</span>
<span class='line-number'>632</span>
<span class='line-number'>633</span>
<span class='line-number'>634</span>
<span class='line-number'>635</span>
<span class='line-number'>636</span>
<span class='line-number'>637</span>
<span class='line-number'>638</span>
<span class='line-number'>639</span>
<span class='line-number'>640</span>
<span class='line-number'>641</span>
<span class='line-number'>642</span>
<span class='line-number'>643</span>
<span class='line-number'>644</span>
<span class='line-number'>645</span>
<span class='line-number'>646</span>
<span class='line-number'>647</span>
<span class='line-number'>648</span>
<span class='line-number'>649</span>
<span class='line-number'>650</span>
<span class='line-number'>651</span>
<span class='line-number'>652</span>
<span class='line-number'>653</span>
<span class='line-number'>654</span>
<span class='line-number'>655</span>
<span class='line-number'>656</span>
<span class='line-number'>657</span>
<span class='line-number'>658</span>
<span class='line-number'>659</span>
<span class='line-number'>660</span>
<span class='line-number'>661</span>
<span class='line-number'>662</span>
<span class='line-number'>663</span>
<span class='line-number'>664</span>
<span class='line-number'>665</span>
<span class='line-number'>666</span>
<span class='line-number'>667</span>
<span class='line-number'>668</span>
<span class='line-number'>669</span>
<span class='line-number'>670</span>
<span class='line-number'>671</span>
<span class='line-number'>672</span>
<span class='line-number'>673</span>
<span class='line-number'>674</span>
<span class='line-number'>675</span>
<span class='line-number'>676</span>
<span class='line-number'>677</span>
<span class='line-number'>678</span>
<span class='line-number'>679</span>
<span class='line-number'>680</span>
<span class='line-number'>681</span>
<span class='line-number'>682</span>
<span class='line-number'>683</span>
<span class='line-number'>684</span>
<span class='line-number'>685</span>
<span class='line-number'>686</span>
<span class='line-number'>687</span>
<span class='line-number'>688</span>
<span class='line-number'>689</span>
<span class='line-number'>690</span>
<span class='line-number'>691</span>
<span class='line-number'>692</span>
<span class='line-number'>693</span>
<span class='line-number'>694</span>
<span class='line-number'>695</span>
<span class='line-number'>696</span>
<span class='line-number'>697</span>
<span class='line-number'>698</span>
<span class='line-number'>699</span>
<span class='line-number'>700</span>
<span class='line-number'>701</span>
<span class='line-number'>702</span>
<span class='line-number'>703</span>
<span class='line-number'>704</span>
<span class='line-number'>705</span>
<span class='line-number'>706</span>
<span class='line-number'>707</span>
<span class='line-number'>708</span>
<span class='line-number'>709</span>
<span class='line-number'>710</span>
<span class='line-number'>711</span>
<span class='line-number'>712</span>
<span class='line-number'>713</span>
<span class='line-number'>714</span>
<span class='line-number'>715</span>
<span class='line-number'>716</span>
<span class='line-number'>717</span>
<span class='line-number'>718</span>
<span class='line-number'>719</span>
<span class='line-number'>720</span>
<span class='line-number'>721</span>
<span class='line-number'>722</span>
<span class='line-number'>723</span>
<span class='line-number'>724</span>
<span class='line-number'>725</span>
<span class='line-number'>726</span>
<span class='line-number'>727</span>
<span class='line-number'>728</span>
<span class='line-number'>729</span>
<span class='line-number'>730</span>
<span class='line-number'>731</span>
<span class='line-number'>732</span>
<span class='line-number'>733</span>
<span class='line-number'>734</span>
<span class='line-number'>735</span>
<span class='line-number'>736</span>
<span class='line-number'>737</span>
<span class='line-number'>738</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>&lt;em&gt;&lt;em&gt;&lt;strong&gt;
</span><span class='line'>&lt;/strong&gt; 数据包入驱动队列后
</span><span class='line'>&lt;/em&gt;&lt;/em&gt;**&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;pre&gt;&lt;code&gt;如果队列排队数据包的总数据量超过当前限制值
</span><span class='line'>禁止数据包入驱动队列
</span><span class='line'>&lt;/code&gt;&lt;/pre&gt;
</span><span class='line'>
</span><span class='line'>&lt;pre&gt;&lt;code&gt;
</span><span class='line'>这里要清楚，被排队的数据量可以超过LIMIT，因为在TSO，UFO或GSO启用的情况下，一个大型的数据包可以通过单个操作入队，因此LIMIT检查在入队之后才发生，如果你很注重延迟，那么可能需要考虑关闭这些功能，本文后面将会提到如何实现这个需求。
</span><span class='line'>
</span><span class='line'>BQL的第二个阶段在硬件完成数据传输后触发（pseudo-code简化版）：
</span><span class='line'>&lt;/code&gt;&lt;/pre&gt;
</span><span class='line'>
</span><span class='line'>&lt;pre&gt;&lt;code&gt;****
</span><span class='line'>** 当硬件已经完成一批次数据包的发送
</span><span class='line'>** (一个周期结束)
</span><span class='line'>****
</span><span class='line'>
</span><span class='line'>如果硬件在一个周期内处于饥饿状态
</span><span class='line'>提高LIMIT
</span><span class='line'>
</span><span class='line'>否则，如果硬件在一个周期内都没有进入饥饿状态，并且仍然有数据需要发送
</span><span class='line'>使LIMIT减少"本周期内留下未发送的数据量"
</span><span class='line'>
</span><span class='line'>如果驱动队列中排队的数据量小于LIMIT
</span><span class='line'>允许数据包入驱动队列
</span><span class='line'>&lt;/code&gt;&lt;/pre&gt;
</span><span class='line'>
</span><span class='line'>&lt;pre&gt;&lt;code&gt;
</span><span class='line'>如你所见，BQL是以测试设备是否被饥饿为基础实现的。如果设备被饥饿，LIMIT值将会增加，允许更多的数据排队，以减少饥饿，如果设备整个周期内都处于忙碌状态并且队列中仍然有数据需要传输，表明队列容量大于当前系统所需，LIMIT值将会降低，以避免延迟的提升。
</span><span class='line'>
</span><span class='line'>BQL对数据排队的影响效果如何？一个真实世界的案例也许可以给你一个感觉。我的一个服务器的驱动队列大小为256个描述符，MTU 1,500字节，意味着最多能有256 * 1,500 = 384,000字节同时排队（TSO，GSO之类的已被关闭，否则这个值将会更高）。然而，由BQL计算的限制值是3,012字节。如你所见，BQL大大地限制了排队数据量。
</span><span class='line'>
</span><span class='line'>BQL的一个有趣方面可以从它名字的第一个词思议——byte（字节）。不像驱动队列和大多数的队列容量，BQL直接操作字节，这是因为字节数与数据包数量相比，能更有效地影响数据传输的延迟。
</span><span class='line'>
</span><span class='line'>BQL通过限制排队的数据量为避免饥饿的最小需求值以降低网络延迟。对于移动大量在入口NIC的驱动队列处排队的数据包到queueing discipline(QDisc)层，BQL起到了非常重要的影响。QDisc层实现了更复杂的排队策略，下一节介绍Linux QDisc层。
</span><span class='line'>
</span><span class='line'>## 排队规则(Queuing Disciplines (QDisc))
</span><span class='line'>
</span><span class='line'>驱动队列是一个很简单的先进先出（FIFO）队列，它平等对待所有数据包，没有区分不同流量数据包的功能。这样的设计优点是保持了驱动程序的简单以及高效。要注意更多高级的以太网络适配器以及绝大多数的无线网络适配器支持多种独立的传输队列，但同样的都是典型的FIFO。较高层的负责选择需要使用的传输队列。
</span><span class='line'>
</span><span class='line'>在IP stack和驱动队列之间的是排队规则（queueing discipline(QDisc)）层（见图1）。这一层实现了内核的流量管理能力，如流量分类，优先级和速率调整。QDisc层通过一些不透明的tc命令进行配置。QDisc层有三个关键的概念需要理解：QDiscs，classes（类）和filters（过滤器）。
</span><span class='line'>
</span><span class='line'>QDisc是Linux对流量队列的一个抽象化，比标准的FIFO队列要复杂得多。这个接口允许QDisc提供复杂的队列管理机制而无需修改IP stack或者NIC驱动。默认地，每一个网络接口都被分配了一个pfifo_fast QDisc，这是一个实现了简单的三频优先方案的队列，排序以数据包的TOS位为基础。尽管这是默认的，pfifo_fast QDisc离最佳选择还很远，因为它默认拥有一个很深的队列（见下文的txqueuelen）并且无法区分流量。
</span><span class='line'>
</span><span class='line'>第二个与QDisc关系很密切的概念是类，独立的QDiscs为了以不同方式处理子集流量，可能实现类。例如，分层令牌桶（Hierarchical Token Bucket (HTB)）QDisc允许用户配置一个500 Kbps和300 Kbps的类，然后根据需要，把流量归为特定类。需要注意，并非所有QDiscs拥有对多个类的支持——那些被称为类的QDiscs。
</span><span class='line'>
</span><span class='line'>过滤器（也被称为分类器），是一个用于流量分类到特定QDisc或类的机制。各种不同的过滤器复杂度不一，u32是一个最通用的也可能是一个最易用的流量过滤器。流量过滤器的文档比较缺乏，不过你可以在此找到使用例子：我的一个QoS脚本。
</span><span class='line'>
</span><span class='line'>更多关于QDiscs，classes和filters的信息，可阅LARTC HOWTO，以及tc的man pages。
</span><span class='line'>
</span><span class='line'>## 传输层与排队规则间的缓冲区
</span><span class='line'>
</span><span class='line'>在前面的图片中，你可能会发现排队规则层并没有数据包队列。这意思是，网络栈直接放置数据包到排队规则中或者当队列已满时直接放回到更上层（例如socket缓冲区）。这很明显的一个问题是，如果接下来有大量数据需要发送，会发送什么？这种情况会在TCP链接发生大量堵塞或者甚至有些应用程序以其最快的速度发送UDP数据包时出现。对于一个持有单个队列的QDisc，与图4中驱动队列同样的问题将会发生，亦即单个大带宽或者高数据包传输速率流会把整个队列的空间消耗完毕，从而导致丢包，极大影响其它流的延迟。更糟糕的是，这产生了另一个缓冲点，其中可以形成standing queue，使得延迟增加并导致了TCP的RTT和拥塞窗口大小计算问题。Linux默认的pfifo_fast QDisc，由于大多数数据包TOS标记为0，因此基本可以视作单个队列，因此这种现象并不罕见。
</span><span class='line'>
</span><span class='line'>Linux 3.6.0（2012-09-30），加入了一个新的特性，称为TCP小型队列，目标是解决上述问题。TCP小型队列限制了每个TCP流每次可在QDisc与驱动队列中排队的字节数。这有一个有趣的影响：内核会更早调度回应用程序，从而允许应用程序以更高效的优先级写入套接字。目前（2012-12-28），其它单个传输流仍然有可能淹没QDisc层。
</span><span class='line'>
</span><span class='line'>另一个解决传输层洪水问题的方案是使用具有多个队列的QDisc，理想情况下每个网络流一个队列。随机公平队列（Stochastic Fairness Queueing (SFQ)）和延迟控制公平队列（Fair Queueing with Controlled Delay (fq_codel)）都有为每个网络流分配一个队列的机制，因此很适合解决这个洪水问题。
</span><span class='line'>
</span><span class='line'>## 如何控制Linux的队列容量
</span><span class='line'>
</span><span class='line'>#### 驱动队列
</span><span class='line'>
</span><span class='line'>ethtool命令可用于控制以太网设备驱动队列容量。ethtool也提供了底层接口分析，可以启用或关闭IP stack和设备的一些特性。
</span><span class='line'>
</span><span class='line'>-g参数可以输出驱动队列的信息：
</span><span class='line'>&lt;/code&gt;&lt;/pre&gt;
</span><span class='line'>
</span><span class='line'>&lt;pre&gt;&lt;code&gt;[root@alpha net-next]# ethtool -g eth0
</span><span class='line'>Ring parameters for eth0:
</span><span class='line'>Pre-set maximums:
</span><span class='line'>RX:        16384
</span><span class='line'>RX Mini:    0
</span><span class='line'>RX Jumbo:    0
</span><span class='line'>TX:        16384
</span><span class='line'>Current hardware settings:
</span><span class='line'>RX:        512
</span><span class='line'>RX Mini:    0
</span><span class='line'>RX Jumbo:    0
</span><span class='line'>TX:        256
</span><span class='line'>&lt;/code&gt;&lt;/pre&gt;
</span><span class='line'>
</span><span class='line'>&lt;pre&gt;&lt;code&gt;
</span><span class='line'>你可以从以上的输出看到本NIC的驱动程序默认拥有一个容量为256描述符的传输队列。早期，在Bufferbloat的探索中，这个队列的容量经常建议减少以降低延迟。随着BQL的使用（假设你的驱动程序支持它），再也没有任何必要去修改驱动队列的容量了（如何配置BQL见下文）。
</span><span class='line'>
</span><span class='line'>Ethtool也允许你管理优化特性，例如TSO，UFO和GSO。-k参数输出当前的offload设置，-K修改它们。
</span><span class='line'>&lt;/code&gt;&lt;/pre&gt;
</span><span class='line'>
</span><span class='line'>&lt;pre&gt;&lt;code&gt;[dan@alpha ~]$ ethtool -k eth0
</span><span class='line'>Offload parameters for eth0:
</span><span class='line'>rx-checksumming: off
</span><span class='line'>tx-checksumming: off
</span><span class='line'>scatter-gather: off
</span><span class='line'>tcp-segmentation-offload: off
</span><span class='line'>udp-fragmentation-offload: off
</span><span class='line'>generic-segmentation-offload: off
</span><span class='line'>generic-receive-offload: on
</span><span class='line'>large-receive-offload: off
</span><span class='line'>rx-vlan-offload: off
</span><span class='line'>tx-vlan-offload: off
</span><span class='line'>ntuple-filters: off
</span><span class='line'>receive-hashing: off
</span><span class='line'>&lt;/code&gt;&lt;/pre&gt;
</span><span class='line'>
</span><span class='line'>&lt;pre&gt;&lt;code&gt;
</span><span class='line'>由于TSO，GSO，UFO和GRO极大的提高了驱动队列中可以排队的字节数，如果你想优化延迟而不是吞吐量，那么你应该关闭这些特性。如果禁用这些特性，除非系统正在处理非常高的数据速率，否则您将不会注意到任何CPU影响或吞吐量降低。
</span><span class='line'>
</span><span class='line'>## Byte Queue Limits (BQL)
</span><span class='line'>
</span><span class='line'>BQL是一个自适应算法，因此一般来说你不需要为此操心。然而，如果你想牺牲数据速率以换得最优延迟，你就需要修改LIMIT的上限值。BQL的状态和设置可以在/sys中NIC的目录找到，在我的服务器上，eth0的BQL目录是：
</span><span class='line'>&lt;/code&gt;&lt;/pre&gt;
</span><span class='line'>
</span><span class='line'>&lt;pre&gt;&lt;code&gt;/sys/devices/pci0000:00/0000:00:14.0/net/eth0/queues/tx-0/byte_queue_limits
</span><span class='line'>&lt;/code&gt;&lt;/pre&gt;
</span><span class='line'>
</span><span class='line'>&lt;pre&gt;&lt;code&gt;在该目录下的文件有：
</span><span class='line'>
</span><span class='line'>  hold_time: 修改LIMIT值的时间间隔，单位为毫秒
</span><span class='line'>
</span><span class='line'>  inflight: 还没发送且在排队的数据量
</span><span class='line'>
</span><span class='line'>  limit: BQL计算的LIMIT值，如果NIC驱动不支持BQL，值为0
</span><span class='line'>
</span><span class='line'>  limit_max: LIMIT的最大值，降低此值可以优化延迟
</span><span class='line'>
</span><span class='line'>  limit_min: LIMIT的最小值，增高此值可以优化吞吐量
</span><span class='line'>
</span><span class='line'>要修改LIMIT的上限值，把你需要的值写入limit_max文件即可，单位为字节：
</span><span class='line'>&lt;/code&gt;&lt;/pre&gt;
</span><span class='line'>
</span><span class='line'>&lt;pre&gt;&lt;code&gt;echo "3000" &gt; limit_max
</span><span class='line'>&lt;/code&gt;&lt;/pre&gt;
</span><span class='line'>
</span><span class='line'>&lt;pre&gt;&lt;code&gt;## 什么是txqueuelen？
</span><span class='line'>
</span><span class='line'>在早期的Bufferbload讨论中，经常会提到静态地减少NIC传输队列长度。当前队列长度值可以通过ip和ifconfig命令取得。令人疑惑的是，这两个命令给了传输队列的长度不同的名字：
</span><span class='line'>&lt;/code&gt;&lt;/pre&gt;
</span><span class='line'>
</span><span class='line'>&lt;pre&gt;&lt;code&gt;[dan@alpha ~]$ ifconfig eth0
</span><span class='line'>eth0      Link encap:Ethernet  HWaddr 00:18:F3:51:44:10
</span><span class='line'>      inet addr:69.41.199.58  Bcast:69.41.199.63  Mask:255.255.255.248
</span><span class='line'>      inet6 addr: fe80::218:f3ff:fe51:4410/64 Scope:Link
</span><span class='line'>      UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1
</span><span class='line'>      RX packets:435033 errors:0 dropped:0 overruns:0 frame:0
</span><span class='line'>      TX packets:429919 errors:0 dropped:0 overruns:0 carrier:0
</span><span class='line'>      collisions:0 txqueuelen:1000
</span><span class='line'>      RX bytes:65651219 (62.6 MiB)  TX bytes:132143593 (126.0 MiB)
</span><span class='line'>      Interrupt:23
</span><span class='line'>&lt;/code&gt;&lt;/pre&gt;
</span><span class='line'>
</span><span class='line'>&lt;pre&gt;&lt;code&gt;&lt;/code&gt;&lt;/pre&gt;
</span><span class='line'>
</span><span class='line'>&lt;pre&gt;&lt;code&gt; [dan@alpha ~]$ ip link
</span><span class='line'>1: lo:  mtu 16436 qdisc noqueue state UNKNOWN
</span><span class='line'>link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
</span><span class='line'>2: eth0:  mtu 1500 qdisc pfifo_fast state UP qlen 1000
</span><span class='line'>link/ether 00:18:f3:51:44:10 brd ff:ff:ff:ff:ff:ff
</span><span class='line'>&lt;/code&gt;&lt;/pre&gt;
</span><span class='line'>
</span><span class='line'>&lt;pre&gt;&lt;code&gt;
</span><span class='line'>Linux默认的传输队列长度为1,000个数据包，这是一个很大的缓冲区，尤其在低带宽的情况下。
</span><span class='line'>
</span><span class='line'>有趣的问题是，这个变量实际上是控制什么？
</span><span class='line'>
</span><span class='line'>我也不清楚，因此我花了点时间深入探索内核源码。我现在能说的，txqueuelen只是用来作为一些排队规则的默认队列长度。例如：
</span><span class='line'>&lt;/code&gt;&lt;/pre&gt;
</span><span class='line'>
</span><span class='line'>&lt;pre&gt;&lt;code&gt;pfifo_fast（Linux默认排队规则）
</span><span class='line'>sch_fifo
</span><span class='line'>sch_gred
</span><span class='line'>sch_htb（只有默认队列）
</span><span class='line'>sch_plug
</span><span class='line'>sch_sfb
</span><span class='line'>sch_teql
</span><span class='line'>&lt;/code&gt;&lt;/pre&gt;
</span><span class='line'>
</span><span class='line'>&lt;pre&gt;&lt;code&gt;
</span><span class='line'>见图1，txqueuelen参数在排队规则中控制以上列出的队列类型的长度。绝大多数这些排队规则，tc的limit参数默认会覆盖掉txqueuelen。总的来说，如果你不是使用上述的排队规则，或者如果你用limit参数指定了队列长度，那么txqueuelen值就没有任何作用。
</span><span class='line'>
</span><span class='line'>顺便一提，我发现一个令人疑惑的地方，ifconfig命令显示了网络接口的底层信息，例如MAC地址，但是txqueuelen却是来自高层的QDisc层，很自然的地，看起来ifconfig会输出驱动队列长度。
</span><span class='line'>
</span><span class='line'>传输队列的长度可以使用ip或ifconfig命令修改：
</span><span class='line'>&lt;/code&gt;&lt;/pre&gt;
</span><span class='line'>
</span><span class='line'>&lt;pre&gt;&lt;code&gt;[root@alpha dan]# ip link set txqueuelen 500 dev eth0
</span><span class='line'>&lt;/code&gt;&lt;/pre&gt;
</span><span class='line'>
</span><span class='line'>&lt;pre&gt;&lt;code&gt;需要注意，ip命令使用"txqueuelen"但是输出时使用"qlen" —— 另一个不幸的不一致性。
</span><span class='line'>
</span><span class='line'>## 排队规则
</span><span class='line'>
</span><span class='line'>正如前文所描述，Linux内核拥有大量的排队规则（QDiscs），每一个都实现了自己的数据包排队方法。讨论如何配置每一个QDiscs已经超出了本文的范围。关于配置这些队列的信息，可以查阅tc的man page（man tc）。你可以使用"man tc qdisc-name"（例如："man tc htb"或"man tc fq_codel"）找到每一个队列的细节。LARTC也是一个很有用的资源，但是缺乏了一些新特性的信息。
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>以下是一些可能对你使用tc命令有用的建议和技巧：
</span><span class='line'>
</span><span class='line'>  HTB QDisc实现了一个接收所有未分类数据包的默认队列。一些如DRR QDiscs会直接把未分类的数据包丢进黑洞。使用命令"tc qdisc show"，通过direct_packets_stat可以检查有多少数据包未被合适分类。
</span><span class='line'>
</span><span class='line'>  HTB类分层只适用于分类，对于带宽分配无效。所有带宽分配通过检查Leaves和它们的优先级进行。
</span><span class='line'>
</span><span class='line'>  QDisc中，使用一个major和一个minor数字作为QDiscs和classes的基本标识，major和minor之间使用英文冒号分隔。tc命令使用十六进制代表这些数字。由于很多字符串，例如10，在十进制和十六进制都是正确的，因此很多用户不知道tc使用十六进制。见我的tc脚本，可以查看我是如何处理这个问题的。
</span><span class='line'>
</span><span class='line'>  如果你正在使用基于ATM的ADSL（绝大多数的DLS服务是基于ATM，新的变体例如VDSL2可能不是），你很可能需要考虑添加一个"linklayer adsl"的选项。这个统计把IP数据包分解成一组53字节的ATM单元所产生的开销。
</span><span class='line'>
</span><span class='line'>  如果你正在使用PPPoE，你很可能需要考虑通过"overhead"参数统计PPPoE开销。
</span><span class='line'>
</span><span class='line'>#### TCP小型队列
</span><span class='line'>
</span><span class='line'>每个TCP Socket的队列限制可以通过/proc中的文件查看或修改：
</span><span class='line'>&lt;/code&gt;&lt;/pre&gt;
</span><span class='line'>
</span><span class='line'>&lt;pre&gt;&lt;code&gt;/proc/sys/net/ipv4/tcp_limit_output_bytes
</span><span class='line'>&lt;/code&gt;&lt;/pre&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;```&lt;/p&gt;
</span><span class='line'>]]&gt;&lt;/content&gt;
</span><span class='line'>  &lt;/entry&gt;
</span><span class='line'>  
</span><span class='line'>  &lt;entry&gt;
</span><span class='line'>&lt;title type="html"&gt;&lt;![CDATA[网桥源码]]&gt;&lt;/title&gt;
</span><span class='line'>&lt;link href="http://abcdxyzk.github.io/blog/2020/11/09/kernel-bridge/"/&gt;
</span><span class='line'>&lt;updated&gt;2020-11-09T17:52:00+08:00&lt;/updated&gt;
</span><span class='line'>&lt;id&gt;http://abcdxyzk.github.io/blog/2020/11/09/kernel-bridge&lt;/id&gt;
</span><span class='line'>&lt;content type="html"&gt;&lt;![CDATA[&lt;p&gt;&lt;a href="https://blog.csdn.net/NW_NW_NW/article/details/75045966"&gt;https://blog.csdn.net/NW_NW_NW/article/details/75045966&lt;/a&gt;&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;&lt;a href="https://blog.csdn.net/NW_NW_NW/article/details/75090101"&gt;https://blog.csdn.net/NW_NW_NW/article/details/75090101&lt;/a&gt;&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;&lt;a href="https://blog.csdn.net/NW_NW_NW/article/details/75647220"&gt;https://blog.csdn.net/NW_NW_NW/article/details/75647220&lt;/a&gt;&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;&lt;a href="https://blog.csdn.net/NW_NW_NW/article/details/76022117"&gt;https://blog.csdn.net/NW_NW_NW/article/details/76022117&lt;/a&gt;&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;&lt;a href="https://blog.csdn.net/NW_NW_NW/article/details/76153027"&gt;https://blog.csdn.net/NW_NW_NW/article/details/76153027&lt;/a&gt;&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;&lt;a href="https://blog.csdn.net/NW_NW_NW/article/details/76204707"&gt;https://blog.csdn.net/NW_NW_NW/article/details/76204707&lt;/a&gt;&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;&lt;a href="https://blog.csdn.net/NW_NW_NW/article/details/76674232"&gt;https://blog.csdn.net/NW_NW_NW/article/details/76674232&lt;/a&gt;&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;&lt;a href="https://blog.csdn.net/NW_NW_NW/article/details/76710941"&gt;https://blog.csdn.net/NW_NW_NW/article/details/76710941&lt;/a&gt;&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;h2&gt;桥初始化&lt;/h2&gt;
</span><span class='line'>
</span><span class='line'>&lt;pre&gt;&lt;code&gt;    static int __init br_init(void)
</span><span class='line'>{
</span><span class='line'>    int err;
</span><span class='line'>    /*注册协议生成树收包函数*/
</span><span class='line'>    err = stp_proto_register(&amp;br_stp_proto);
</span><span class='line'>    if (err &lt; 0) {
</span><span class='line'>        pr_err("bridge: can't register sap for STP\n");
</span><span class='line'>        return err;
</span><span class='line'>    }
</span><span class='line'>    /*转发数据库初始化*/
</span><span class='line'>    err = br_fdb_init();
</span><span class='line'>    if (err)
</span><span class='line'>        goto err_out;
</span><span class='line'>    /*在/proc目录下生成任何与bridge相关的目录，如果我们想在/proc下生成bridge相关的子目录或子文件*/
</span><span class='line'>    err = register_pernet_subsys(&amp;br_net_ops);
</span><span class='line'>    if (err)
</span><span class='line'>        goto err_out1;
</span><span class='line'>    /*目前好像没有什么实际作用，在内核中所注册的函数为空*/
</span><span class='line'>    err = br_nf_core_init();
</span><span class='line'>    if (err)
</span><span class='line'>        goto err_out2;
</span><span class='line'>    /*注册相关网络设备的事件通知连*/
</span><span class='line'>    err = register_netdevice_notifier(&amp;br_device_notifier);
</span><span class='line'>    if (err)
</span><span class='line'>        goto err_out3;
</span><span class='line'>
</span><span class='line'>    /*注册通知连，主要针对桥转发表事件的相关信息*/
</span><span class='line'>    err = register_switchdev_notifier(&amp;br_switchdev_notifier);
</span><span class='line'>    if (err)
</span><span class='line'>        goto err_out4;
</span><span class='line'>    /*进行netlink的初始化*/
</span><span class='line'>    err = br_netlink_init();
</span><span class='line'>    if (err)
</span><span class='line'>        goto err_out5;
</span><span class='line'>
</span><span class='line'>    /*用来处理ioctl命令的函数，比如添加和删除网桥*/
</span><span class='line'>    brioctl_set(br_ioctl_deviceless_stub);
</span><span class='line'>
</span><span class='line'>#if IS_ENABLED(CONFIG_ATM_LANE)
</span><span class='line'>    br_fdb_test_addr_hook = br_fdb_test_addr;
</span><span class='line'>#endif
</span><span class='line'>    return 0;
</span><span class='line'>}
</span><span class='line'>&lt;/code&gt;&lt;/pre&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt; 了解了桥初始化大致要做的事情后，我们再来看看这些初始化或者注册的事情到底干了些什么？&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;1.注册协议生成树收包函数stp_proto_register&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;在桥初始化的时候，注册了一个br_stp_proto参数，此参数的具体模样是这样子的&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;pre&gt;&lt;code&gt;    static const struct stp_proto br_stp_proto = {
</span><span class='line'>    .rcv   = br_stp_rcv,
</span><span class='line'>};
</span><span class='line'>&lt;/code&gt;&lt;/pre&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;br_stp_rcv函数在/net/bridge/br_stp_bpdu.c中主要针对网桥进行协议交换的帧（BPDU）进行配置操作。&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;2.桥转发数据库初始化br_fdb_init&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;此函数就是在内存中建立一块slab cache，以存放net_bridge_fdb_entry&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;其中：net_bridge_fdb_entry是一个结构体，用来转发数据库的记录项网桥所学到对的每个MAC地址都有这样一个记录&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;3.在proc目录下生成相关文件的注册函数register_pernet_subsys，初始化的时候给这个函数传递了一个参数br_net_ops，这个参数的模样是这样的&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;pre&gt;&lt;code&gt;    static struct pernet_operations br_net_ops = {
</span><span class='line'>    .exit   = br_net_exit,
</span><span class='line'>};
</span><span class='line'>&lt;/code&gt;&lt;/pre&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;但是在桥初始化的时候，仅仅注册了br_net_exit，这个函数会将桥下面的所有文件全部清空。&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;4.通知链的相关函数注册register_netdevice_notifier这个注册函数主要针对设备信息的变化，注册参数br_device_notifier，具体如下：&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;pre&gt;&lt;code&gt;    static struct notifier_block br_device_notifier = {
</span><span class='line'>    .notifier_call = br_device_event
</span><span class='line'>};
</span><span class='line'>&lt;/code&gt;&lt;/pre&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;br_device_event函数是用来当桥上的设备状态或者设备信息发生改变时做相应的处理，该函数在/net/bridge/br.c中&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;5.注册通知连，主要针对桥转发表事件的相关信息register_switchdev_notifier，传入的参数br_switchdev_notifier详细信息如下：&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;pre&gt;&lt;code&gt;    static struct notifier_block br_switchdev_notifier = {
</span><span class='line'>    .notifier_call = br_switchdev_event,
</span><span class='line'>};
</span><span class='line'>&lt;/code&gt;&lt;/pre&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;br_switchdev_event，主要针对桥转发表的事件做出相应的处理该函数在/net/bridge/br.c中&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;6.brioctl_set用来处理ioctl命令的函数，比如添加和删除网桥，br_ioctl_deviceless_stub给回调函数br_ioctl_hook,而br_ioctl_hook在sock_ioctl中&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;使用，这样通过在应用层调用socket的ioctl函数，就能够进行网桥的添加与删除了，函数用来处理添加和删除网桥的相关操作&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;以上就是网桥初始化的相关操作。&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;h2&gt;添加一个桥设备——br_add_bridge&lt;/h2&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;我们先来看一个命令：brctl addbr br1&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;上节我们提到一个用来处理ioctl命令的函数br_ioctl_deviceless_stub通过调用brioctl_set，
</span><span class='line'>将br_ioctl_deviceless_stub赋值给回调函数br_ioctl_hook，而br_ioctl_hook在sock_ioctl中使用。
</span><span class='line'>这样通过在应用层调用socket的ioctl函数，就能够进行网桥的添加与删除了。&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;如果我们想增加新的ioctl，用于我们新开放的功能，就可以在该函数里增加新的case即可。&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;当我们输入上面命令时，就会触发br_ioctl_deviceless_stub函数来响应br_add_bridge函数，当命令执行完成以后，
</span><span class='line'>使用brctl show命令就可以看见我们添加的br1这个网桥设备已经生成。&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;pre&gt;&lt;code&gt;    int br_ioctl_deviceless_stub(struct net *net, unsigned int cmd, void __user *uarg)
</span><span class='line'>{
</span><span class='line'>    switch (cmd) {
</span><span class='line'>    case SIOCGIFBR:
</span><span class='line'>    case SIOCSIFBR:
</span><span class='line'>        return old_deviceless(net, uarg);
</span><span class='line'>
</span><span class='line'>    case SIOCBRADDBR:
</span><span class='line'>    case SIOCBRDELBR:
</span><span class='line'>    {
</span><span class='line'>        char buf[IFNAMSIZ];
</span><span class='line'>
</span><span class='line'>        if (!ns_capable(net-&gt;user_ns, CAP_NET_ADMIN))
</span><span class='line'>            return -EPERM;
</span><span class='line'>
</span><span class='line'>        if (copy_from_user(buf, uarg, IFNAMSIZ))
</span><span class='line'>            return -EFAULT;
</span><span class='line'>
</span><span class='line'>        buf[IFNAMSIZ-1] = 0;
</span><span class='line'>        if (cmd == SIOCBRADDBR)
</span><span class='line'>            return br_add_bridge(net, buf);/*添加网桥设备的操作*/
</span><span class='line'>
</span><span class='line'>        return br_del_bridge(net, buf);
</span><span class='line'>    }
</span><span class='line'>    }
</span><span class='line'>    return -EOPNOTSUPP;
</span><span class='line'>}
</span><span class='line'>&lt;/code&gt;&lt;/pre&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;该函数注册在，桥设备添加时候dev-&gt;netdev_ops = &amp;br_netdev_ops;
</span><span class='line'> 在br_netdev_ops有一个函数指针.ndo_do_ioctl= br_dev_ioctl&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;pre&gt;&lt;code&gt;    int br_add_if(struct net_bridge *br, struct net_device *dev)
</span><span class='line'>{
</span><span class='line'>    struct net_bridge_port *p;
</span><span class='line'>    int err = 0;
</span><span class='line'>    unsigned br_hr, dev_hr;
</span><span class='line'>    bool changed_addr;
</span><span class='line'>
</span><span class='line'>    /* Don't allow bridging non-ethernet like devices, or DSA-enabled
</span><span class='line'>     * master network devices since the bridge layer rx_handler prevents
</span><span class='line'>     * the DSA fake ethertype handler to be invoked, so we do not strip off
</span><span class='line'>     * the DSA switch tag protocol header and the bridge layer just return
</span><span class='line'>     * RX_HANDLER_CONSUMED, stopping RX processing for these frames.
</span><span class='line'>     */
</span><span class='line'>
</span><span class='line'>    if ((dev-&gt;flags &amp; IFF_LOOPBACK) ||
</span><span class='line'>        dev-&gt;type != ARPHRD_ETHER || dev-&gt;addr_len != ETH_ALEN ||
</span><span class='line'>        !is_valid_ether_addr(dev-&gt;dev_addr) ||
</span><span class='line'>        netdev_uses_dsa(dev))
</span><span class='line'>        return -EINVAL;
</span><span class='line'>
</span><span class='line'>    /* No bridging of bridges */
</span><span class='line'>    if (dev-&gt;netdev_ops-&gt;ndo_start_xmit == br_dev_xmit)
</span><span class='line'>        return -ELOOP;
</span><span class='line'>
</span><span class='line'>    /* Device is already being bridged  */
</span><span class='line'>    if (br_port_exists(dev))
</span><span class='line'>        return -EBUSY;
</span><span class='line'>
</span><span class='line'>    /* No bridging devices that dislike that (e.g. wireless) */
</span><span class='line'>    if (dev-&gt;priv_flags &amp; IFF_DONT_BRIDGE)
</span><span class='line'>        return -EOPNOTSUPP;
</span><span class='line'>
</span><span class='line'>    /*分配一个新网桥端口并对其初始化*/
</span><span class='line'>    p = new_nbp(br, dev);
</span><span class='line'>    if (IS_ERR(p))
</span><span class='line'>        return PTR_ERR(p);
</span><span class='line'>
</span><span class='line'>    /*调用设备通知链，告诉网络有这样一个设备*/
</span><span class='line'>    call_netdevice_notifiers(NETDEV_JOIN, dev);
</span><span class='line'>
</span><span class='line'>    /**向设备添加或删除所有多播帧的接收。*/
</span><span class='line'>    err = dev_set_allmulti(dev, 1);
</span><span class='line'>    if (err)
</span><span class='line'>        goto put_back;
</span><span class='line'>
</span><span class='line'>    err = kobject_init_and_add(&amp;p-&gt;kobj, &amp;brport_ktype, &amp;(dev-&gt;dev.kobj),
</span><span class='line'>                   SYSFS_BRIDGE_PORT_ATTR);
</span><span class='line'>    if (err)
</span><span class='line'>        goto err1;
</span><span class='line'>    /*把链路添加到sysfs*/
</span><span class='line'>    err = br_sysfs_addif(p);
</span><span class='line'>    if (err)
</span><span class='line'>        goto err2;
</span><span class='line'>
</span><span class='line'>    err = br_netpoll_enable(p);
</span><span class='line'>    if (err)
</span><span class='line'>        goto err3;
</span><span class='line'>
</span><span class='line'>    /*注册设备接收帧函数*/
</span><span class='line'>    err = netdev_rx_handler_register(dev, br_handle_frame, p);
</span><span class='line'>    if (err)
</span><span class='line'>        goto err4;
</span><span class='line'>
</span><span class='line'>    /*给该端口指派默认优先权*/
</span><span class='line'>    dev-&gt;priv_flags |= IFF_BRIDGE_PORT;
</span><span class='line'>
</span><span class='line'>    /*向上级设备添加主链路*/
</span><span class='line'>    err = netdev_master_upper_dev_link(dev, br-&gt;dev, NULL, NULL);
</span><span class='line'>    if (err)
</span><span class='line'>        goto err5;
</span><span class='line'>
</span><span class='line'>    /*禁用网络设备上的大型接收卸载（LRO）。
</span><span class='line'>    必须在RTNL下调用。
</span><span class='line'>    如果接收到的数据包可能转发到另一个接口，
</span><span class='line'>    则需要这样做。*/
</span><span class='line'>    dev_disable_lro(dev);
</span><span class='line'>
</span><span class='line'>    list_add_rcu(&amp;p-&gt;list, &amp;br-&gt;port_list);
</span><span class='line'>    /*更新桥上的端口数,如果有更新，再进一步将其设为混杂模式*/
</span><span class='line'>    nbp_update_port_count(br);
</span><span class='line'>    /* 重新计算dev-&gt;features并发送通知（如果已更改）。
</span><span class='line'>    应该调用驱动程序或硬件依赖条件可能会改变影响功能。*/
</span><span class='line'>    netdev_update_features(br-&gt;dev);
</span><span class='line'>
</span><span class='line'>    br_hr = br-&gt;dev-&gt;needed_headroom;
</span><span class='line'>    dev_hr = netdev_get_fwd_headroom(dev);
</span><span class='line'>    if (br_hr &lt; dev_hr)
</span><span class='line'>        update_headroom(br, dev_hr);
</span><span class='line'>    else
</span><span class='line'>        netdev_set_rx_headroom(dev, br_hr);
</span><span class='line'>
</span><span class='line'>    /*把dev的mac添加到转发数据库中*/
</span><span class='line'>    if (br_fdb_insert(br, p, dev-&gt;dev_addr, 0))
</span><span class='line'>        netdev_err(dev, "failed insert local address bridge forwarding table\n");
</span><span class='line'>
</span><span class='line'>    /*初始化该桥端口的vlan*/
</span><span class='line'>    err = nbp_vlan_init(p);
</span><span class='line'>    if (err) {
</span><span class='line'>        netdev_err(dev, "failed to initialize vlan filtering on this port\n");
</span><span class='line'>        goto err6;
</span><span class='line'>    }
</span><span class='line'>
</span><span class='line'>    spin_lock_bh(&amp;br-&gt;lock);
</span><span class='line'>    /*更新网桥id*/
</span><span class='line'>    changed_addr = br_stp_recalculate_bridge_id(br);
</span><span class='line'>    /*设备是否启动，桥是否启动，设备上是否有载波信号(网桥没有载波状态，因为网桥是虚拟设备)*/
</span><span class='line'>    if (netif_running(dev) &amp;&amp; netif_oper_up(dev) &amp;&amp;
</span><span class='line'>        (br-&gt;dev-&gt;flags &amp; IFF_UP))
</span><span class='line'>        /*启动网桥端口*/
</span><span class='line'>        br_stp_enable_port(p);
</span><span class='line'>    spin_unlock_bh(&amp;br-&gt;lock);
</span><span class='line'>
</span><span class='line'>    br_ifinfo_notify(RTM_NEWLINK, p);
</span><span class='line'>    /*如果网桥的地址改变，则调用通知连相关的函数*/
</span><span class='line'>    if (changed_addr)
</span><span class='line'>        call_netdevice_notifiers(NETDEV_CHANGEADDR, br-&gt;dev);
</span><span class='line'>    /*更新网桥mtu*/
</span><span class='line'>    dev_set_mtu(br-&gt;dev, br_min_mtu(br));
</span><span class='line'>    br_set_gso_limits(br);
</span><span class='line'>    /*添加一个内核对象*/
</span><span class='line'>    kobject_uevent(&amp;p-&gt;kobj, KOBJ_ADD);
</span><span class='line'>
</span><span class='line'>    return 0;
</span><span class='line'>
</span><span class='line'>err6:
</span><span class='line'>    list_del_rcu(&amp;p-&gt;list);
</span><span class='line'>    br_fdb_delete_by_port(br, p, 0, 1);
</span><span class='line'>    nbp_update_port_count(br);
</span><span class='line'>    netdev_upper_dev_unlink(dev, br-&gt;dev);
</span><span class='line'>
</span><span class='line'>err5:
</span><span class='line'>    dev-&gt;priv_flags &amp;= ~IFF_BRIDGE_PORT;
</span><span class='line'>    netdev_rx_handler_unregister(dev);
</span><span class='line'>err4:
</span><span class='line'>    br_netpoll_disable(p);
</span><span class='line'>err3:
</span><span class='line'>    sysfs_remove_link(br-&gt;ifobj, p-&gt;dev-&gt;name);
</span><span class='line'>err2:
</span><span class='line'>    kobject_put(&amp;p-&gt;kobj);
</span><span class='line'>    p = NULL; /* kobject_put frees */
</span><span class='line'>err1:
</span><span class='line'>    dev_set_allmulti(dev, -1);
</span><span class='line'>put_back:
</span><span class='line'>    dev_put(dev);
</span><span class='line'>    kfree(p);
</span><span class='line'>    return err;
</span><span class='line'>}
</span><span class='line'>&lt;/code&gt;&lt;/pre&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;在桥上添加接口的基本步骤，如上，删除桥端口，主要是把建立接口时所做的事情撤销，如添加接口出错时的一些处理。&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;h2&gt;桥设备及端口的开启和关闭&lt;/h2&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;关于设备的添加删除的基本动作，我们已经知道。
</span><span class='line'>这节，我们看看关于网桥设备以及桥设备上的端口的启动和关闭。&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;我们说过，在初始化一个桥设备的时候有这样一个操作：
</span><span class='line'>dev-&gt;netdev_ops = &amp;br_netdev_ops；&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;br_netdev_ops这个参数，注册了很多函数，其中包括网桥设备的启动和关闭函数&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;br_dev_open和br_dev_stop,这两个函数的工作主要是初始化桥设备的一些队列和
</span><span class='line'>桥设备上端口的一些启动和关闭动作。&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;h4&gt;启动和关闭网桥设备&lt;/h4&gt;
</span><span class='line'>
</span><span class='line'>&lt;pre&gt;&lt;code&gt;    static int br_dev_open(struct net_device *dev)
</span><span class='line'>{
</span><span class='line'>    struct net_bridge *br = netdev_priv(dev);
</span><span class='line'>    /*重新更新网桥设备功能*/
</span><span class='line'>    netdev_update_features(dev);
</span><span class='line'>    /*函数启动进行设备传输*/
</span><span class='line'>    netif_start_queue(dev);
</span><span class='line'>    /*启动网桥设备*/
</span><span class='line'>    br_stp_enable_bridge(br);
</span><span class='line'>    /*初始化网桥本身的多播对列*/
</span><span class='line'>    br_multicast_open(br);
</span><span class='line'>    return 0;
</span><span class='line'>}
</span><span class='line'>&lt;/code&gt;&lt;/pre&gt;
</span><span class='line'>
</span><span class='line'>&lt;pre&gt;&lt;code&gt;    static int br_dev_stop(struct net_device *dev)
</span><span class='line'>{
</span><span class='line'>    struct net_bridge *br = netdev_priv(dev);
</span><span class='line'>    /*关闭网桥设备*/
</span><span class='line'>    br_stp_disable_bridge(br);
</span><span class='line'>    /*关闭网桥设备的多播队列*/
</span><span class='line'>    br_multicast_stop(br);
</span><span class='line'>    /*关闭设备的传输，任何企图在设备上传输信息的尝试都会被拒绝*/
</span><span class='line'>    netif_stop_queue(dev);
</span><span class='line'>
</span><span class='line'>    return 0;
</span><span class='line'>}
</span><span class='line'>&lt;/code&gt;&lt;/pre&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;启动网桥设备，当启动网桥设备时，先前绑定在该设备上的端口也会跟着启动&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;pre&gt;&lt;code&gt;    void br_stp_enable_bridge(struct net_bridge *br)
</span><span class='line'>{
</span><span class='line'>    struct net_bridge_port *p;
</span><span class='line'>    /*锁定网桥*/
</span><span class='line'>    spin_lock_bh(&amp;br-&gt;lock);
</span><span class='line'>    if (br-&gt;stp_enabled == BR_KERNEL_STP)
</span><span class='line'>        mod_timer(&amp;br-&gt;hello_timer, jiffies + br-&gt;hello_time);
</span><span class='line'>
</span><span class='line'>    /* 当网桥启动时，设置次定时器，1/10秒到期一次 */
</span><span class='line'>    mod_timer(&amp;br-&gt;gc_timer, jiffies + HZ/10);
</span><span class='line'>    /*TX配置bpdu*/
</span><span class='line'>    br_config_bpdu_generation(br);
</span><span class='line'>
</span><span class='line'>    list_for_each_entry(p, &amp;br-&gt;port_list, list) {
</span><span class='line'>        if (netif_running(p-&gt;dev) &amp;&amp; netif_oper_up(p-&gt;dev))
</span><span class='line'>            br_stp_enable_port(p);/*启动网桥设备的每个端口*/
</span><span class='line'>    }
</span><span class='line'>    /*给网桥解锁*/
</span><span class='line'>    spin_unlock_bh(&amp;br-&gt;lock);
</span><span class='line'>}
</span><span class='line'>&lt;/code&gt;&lt;/pre&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;关闭网桥设备&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;pre&gt;&lt;code&gt;    void br_stp_disable_bridge(struct net_bridge *br)
</span><span class='line'>{
</span><span class='line'>    struct net_bridge_port *p;
</span><span class='line'>
</span><span class='line'>    spin_lock_bh(&amp;br-&gt;lock);
</span><span class='line'>    list_for_each_entry(p, &amp;br-&gt;port_list, list) {
</span><span class='line'>        if (p-&gt;state != BR_STATE_DISABLED)
</span><span class='line'>            br_stp_disable_port(p);/*关闭网桥设备的每个端口*/
</span><span class='line'>    }
</span><span class='line'>    /*重新设置拓扑标识*/
</span><span class='line'>    br-&gt;topology_change = 0;
</span><span class='line'>    br-&gt;topology_change_detected = 0;
</span><span class='line'>    spin_unlock_bh(&amp;br-&gt;lock);
</span><span class='line'>
</span><span class='line'>    /*删除在初始化桥设备时的定时器*/
</span><span class='line'>    del_timer_sync(&amp;br-&gt;hello_timer);
</span><span class='line'>    del_timer_sync(&amp;br-&gt;topology_change_timer);
</span><span class='line'>    del_timer_sync(&amp;br-&gt;tcn_timer);
</span><span class='line'>    del_timer_sync(&amp;br-&gt;gc_timer);
</span><span class='line'>}
</span><span class='line'>&lt;/code&gt;&lt;/pre&gt;
</span><span class='line'>
</span><span class='line'>&lt;h3&gt;启动和关闭网桥端口&lt;/h3&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;要启动网桥端口，必须满足下列几个条件&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;1.被管理的相关设备已用管理手段启动&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;2.被绑定的相关设备有载波状态&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;3.相关的网桥设备已用管理手段启动&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;注意：网桥设备上没有载波状态，因为网桥是虚拟设备。&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;当网桥是以用户空间命令建起来并且先前三个条件都满足时，该网桥端口就可以立即启用了&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;但是，假设当端口建立时，由于上述三项条件至少有一项不满足无法启动端口时，下面的条件是
</span><span class='line'>每项条件最终满足时启用端口的场合：&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;1.当被关闭的网桥设备重新启动时，其所有关闭的端口就会启用&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;2.当被绑定的设备检测到载波状态时，桥程序会收到NETDE_CHANGE通知消息&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;3.当被关掉的版定设备重启时，桥程序会收到NETDEV_UP的通知消息&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;如若还不满足，网桥端口就会被关闭&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;h4&gt;启动网桥上的端口&lt;/h4&gt;
</span><span class='line'>
</span><span class='line'>&lt;pre&gt;&lt;code&gt;    void br_stp_enable_port(struct net_bridge_port *p)
</span><span class='line'>{
</span><span class='line'>    /*初始化端口*/
</span><span class='line'>    br_init_port(p);
</span><span class='line'>    /*遍历所有端口，为端口指定合适的状态*/
</span><span class='line'>    br_port_state_selection(p-&gt;br);
</span><span class='line'>    /*捕捉一个端口变化信息的通知*/
</span><span class='line'>    br_ifinfo_notify(RTM_NEWLINK, p);
</span><span class='line'>}
</span><span class='line'>&lt;/code&gt;&lt;/pre&gt;
</span><span class='line'>
</span><span class='line'>&lt;h4&gt;关闭网桥上的端口&lt;/h4&gt;
</span><span class='line'>
</span><span class='line'>&lt;pre&gt;&lt;code&gt;    void br_stp_disable_port(struct net_bridge_port *p)
</span><span class='line'>{
</span><span class='line'>    struct net_bridge *br = p-&gt;br;
</span><span class='line'>    int wasroot;
</span><span class='line'>    /*判断是否是根网桥*/
</span><span class='line'>    wasroot = br_is_root_bridge(br);
</span><span class='line'>    /*分配制定角色*/
</span><span class='line'>    br_become_designated_port(p);
</span><span class='line'>    /*将关闭位置位*/
</span><span class='line'>    br_set_state(p, BR_STATE_DISABLED);
</span><span class='line'>    p-&gt;topology_change_ack = 0;
</span><span class='line'>    p-&gt;config_pending = 0;
</span><span class='line'>
</span><span class='line'>    br_ifinfo_notify(RTM_NEWLINK, p);
</span><span class='line'>    /*删除定时器*/
</span><span class='line'>    del_timer(&amp;p-&gt;message_age_timer);
</span><span class='line'>    del_timer(&amp;p-&gt;forward_delay_timer);
</span><span class='line'>    del_timer(&amp;p-&gt;hold_timer);
</span><span class='line'>    /*更改转发表信息*/
</span><span class='line'>    br_fdb_delete_by_port(br, p, 0, 0);
</span><span class='line'>    br_multicast_disable_port(p);
</span><span class='line'>    /*更改桥的bpdu信息*/
</span><span class='line'>    br_configuration_update(br);
</span><span class='line'>    /*更新所有桥上端口的状态*/
</span><span class='line'>    br_port_state_selection(br);
</span><span class='line'>    /*处理非根网桥到根网桥的转移*/
</span><span class='line'>    if (br_is_root_bridge(br) &amp;&amp; !wasroot)
</span><span class='line'>        br_become_root_bridge(br);
</span><span class='line'>}
</span><span class='line'>&lt;/code&gt;&lt;/pre&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;注意，当网桥端口关闭时，非根网桥可能会变成根网桥&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;h2&gt;skb桥转发蓝图&lt;/h2&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;&lt;img src="/images/kernel/20201109-10.png" alt="" /&gt;&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;需要说明的是：&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;1.我们先暂时忽略数据包从一开始是怎么从驱动进入到netif_receive_skb的，因为这个暂时不影响我们理解这幅图的流程。&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;2.由于桥转发的篇幅较大，图中没有标示出，数据包中途被丢弃的情况。约定数据包会发送成功。&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;现在数据包(skb)已经准备好了装备要闯关了&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;1.首先skb从驱动经过繁杂的路线走到了netif_receive_skb这个函数中经过一些小波折到达&lt;code&gt;__netif_receive_skb_core&lt;/code&gt;中时遇到了第一个十字路口是看了看自己有没有skb-&gt;dev-&gt;rx_handler(注1)这个装备，如果有，则进入br_handle_frame(注2).如果没有则直接上协议栈。&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;注1：桥下的设备注册过rx_handler函数，所以数据包会进入桥，br_pass_frame_up函数将原先的设备换成了桥设备， 而桥设备没有注册过rx_handler函数，所以数据包不会二次进入桥。&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;注2：br_handle_frame我们在前几节提到过，是skb进入桥的入口函数，在br_add_if的时候会注册该函数。&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;2.skb注定要经历一番劫难，刚进入br_handle_frame又将陷入两难境地，此时有两个入口，这两个是netfilter设下的连个hook点，分别是，NF_BR_PRE_ROUTING，和NF_BR_LOCAL_IN，两种路径，如果数据包只想去本地，则会选择NF_BR_LOCAL_IN入口，然后发往本地，如果暂时还确定不了，则先进入NF_BR_PRE_ROUTING入口.&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;3.进入NF_BR_PRE_ROUTING入口后，会遇到br_handle_frame_finish函数，这个函数决定了skb的何去何从，(1)如果是转发，则在经过NF_BR_FORWARD钩子点进入转发阶段的障碍，最后在进入NF_BR_POST_ROUTING，以及最终的dev_queue_xmit，实现最终转发。(2)如果发往本地则重新进入NF_BR_LOCAL_IN最后在进入netif_receive_skb，进行转发。skb在经过目前口述的磨练最终得以释放。&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;4.如果是如果是本地发出的数据包，经过NF_BR_LOCAL_OUT钩子点然后进入最后阶段的NF_BR_POST_ROUTING，进行相应的转发。&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;h2&gt;桥数据包接收&mdash;-br_handle_frame&lt;/h2&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;一个很重要的函数br_handle_frame这个函数的初始注册地点是在桥添加接口的时候，注册在桥某一个接口上&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;pre&gt;&lt;code&gt;    int br_add_if(struct net_bridge *br, struct net_device *dev)
</span><span class='line'>{
</span><span class='line'>    ........
</span><span class='line'>    /*注册设备接收帧函数*/
</span><span class='line'>    err = netdev_rx_handler_register(dev, br_handle_frame, p);
</span><span class='line'>    ........
</span><span class='line'>}
</span><span class='line'>&lt;/code&gt;&lt;/pre&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;其次，那么&lt;code&gt;__netif_receive_skb_core&lt;/code&gt;是怎样让数据包进入桥的呢？我们看看上面提到的netdev_rx_handler_register函数，具体做了什么</span></code></pre></td></tr></table></div></figure>
    int netdev_rx_handler_register(struct net_device <em>dev,
                       rx_handler_func_t </em>rx_handler,
                       void *rx_handler_data)
    {
        ASSERT_RTNL();</p>

<pre><code>    if (dev-&gt;rx_handler)
        return -EBUSY;
    /* Note: rx_handler_data must be set before rx_handler */
    /*将dev-&gt;rx_handler_data，指向rx_handler_data(上面的p是桥端口信息)*/
    rcu_assign_pointer(dev-&gt;rx_handler_data, rx_handler_data);
    /*将dev-&gt;rx_handle指针指向rx_handler*/
    rcu_assign_pointer(dev-&gt;rx_handler, rx_handler);

    return 0;
}
</code></pre>

<pre><code>
看完这个函数，我们就明白了为什么在`__netif_receive_skb_core`中可以用skb-&gt;dev-&gt;rx_handle将数据包传入br_handle_frame函数，也就是将数据包传入了桥。

值得注意的是：上面的dev是桥下的设备，不是桥设备，桥设备(比如br0)是没有注册rx_handle这个函数的


好，了解到，桥的注册函数和如何接收数据包后，然后一起来看看br_handle_frame是如何操作的
</code></pre>

<pre><code>/*
 * Return NULL if skb is handled
 * note: already called with rcu_read_lock
 */
rx_handler_result_t br_handle_frame(struct sk_buff **pskb)
{
    struct net_bridge_port *p;
    struct sk_buff *skb = *pskb;
    const unsigned char *dest = eth_hdr(skb)-&gt;h_dest;
    br_should_route_hook_t *rhook;

    if (unlikely(skb-&gt;pkt_type == PACKET_LOOPBACK))
        return RX_HANDLER_PASS;
    /*判断是否是有效的mac地址，即不是多播地址也不是全00地址*/
    if (!is_valid_ether_addr(eth_hdr(skb)-&gt;h_source))
        goto drop;
    /*判断是否是共享数据包，若果是则clone该数据包*/
    skb = skb_share_check(skb, GFP_ATOMIC);
    if (!skb)
        return RX_HANDLER_CONSUMED;
    /*获取数据包网桥端口的一些信息*/
    p = br_port_get_rcu(skb-&gt;dev);
    /*BPDU是网桥之间交流的报文，目标mac是 01:80:C2:00:00:00*/
    if (unlikely(is_link_local_ether_addr(dest))) {
        u16 fwd_mask = p-&gt;br-&gt;group_fwd_mask_required;

        /*
         * See IEEE 802.1D Table 7-10 Reserved addresses
         *
         * Assignment               Value
         * Bridge Group Address     01-80-C2-00-00-00
         * (MAC Control) 802.3      01-80-C2-00-00-01
         * (Link Aggregation) 802.3 01-80-C2-00-00-02
         * 802.1X PAE address       01-80-C2-00-00-03
         *
         * 802.1AB LLDP         01-80-C2-00-00-0E
         *
         * Others reserved for future standardization
         */
        switch (dest[5]) {
        case 0x00:  /* Bridge Group Address */
            /* If STP is turned off,
               then must forward to keep loop detection */
            if (p-&gt;br-&gt;stp_enabled == BR_NO_STP ||
                fwd_mask &amp; (1u &lt;&lt; dest[5]))
                goto forward;
            *pskb = skb;
            __br_handle_local_finish(skb);
            return RX_HANDLER_PASS;

        case 0x01:  /* IEEE MAC (Pause) */
            goto drop;

        case 0x0E:  /* 802.1AB LLDP */
            fwd_mask |= p-&gt;br-&gt;group_fwd_mask;
            if (fwd_mask &amp; (1u &lt;&lt; dest[5]))
                goto forward;
            *pskb = skb;
            __br_handle_local_finish(skb);
            return RX_HANDLER_PASS;

        default:
            /* Allow selective forwarding for most other protocols */
            fwd_mask |= p-&gt;br-&gt;group_fwd_mask;
            if (fwd_mask &amp; (1u &lt;&lt; dest[5]))
                goto forward;
        }

        /* Deliver packet to local host only */
        NF_HOOK(NFPROTO_BRIDGE, NF_BR_LOCAL_IN, dev_net(skb-&gt;dev),
            NULL, skb, skb-&gt;dev, NULL, br_handle_local_finish);
        return RX_HANDLER_CONSUMED;
    }

forward:
    switch (p-&gt;state) {
    case BR_STATE_FORWARDING:
        /*ebtables获取路由的hook点*/
        rhook = rcu_dereference(br_should_route_hook);
        if (rhook) {/*如果是转发状态，则转发数据包，然后返回*/
            if ((*rhook)(skb)) {
                *pskb = skb;
                return RX_HANDLER_PASS;
            }
            dest = eth_hdr(skb)-&gt;h_dest;
        }
        /* fall through */
    case BR_STATE_LEARNING:
        /*目的地址是否是设备链路层地址 */
        if (ether_addr_equal(p-&gt;br-&gt;dev-&gt;dev_addr, dest))
            skb-&gt;pkt_type = PACKET_HOST;
        /*将数据包送入数据帧处理函数br_handle_frame_finish*/
        NF_HOOK(NFPROTO_BRIDGE, NF_BR_PRE_ROUTING,
            dev_net(skb-&gt;dev), NULL, skb, skb-&gt;dev, NULL,
            br_handle_frame_finish);
        break;
    default:
drop:
        kfree_skb(skb);
    }
    return RX_HANDLER_CONSUMED;
}
</code></pre>

<pre><code>
在br_handle_frame主要做一件事，就是将数据包放进那个钩子点。


说明：br_handle_frame函数中有两个hook函数，br_handle_local_finish和br_handle_frame_finish这两个函数只有在netfilter因其他原因没有丢弃或者消化该帧时才会被调用，ebtables也能查看帧。ebtables是一个架构，能提供一些netfilter所没有的提供的额外功能，尤其是，ebtables可以过滤和修改任何类型的帧，而非仅限于那些携带ip封包的帧。

## 桥数据包处理函数——br_handle_frame_finish

br_handle_frame_finish.
作用：br_handle_frame_finish函数主要是决策将不同类别的数据包做不同的分发路径。

其函数处理的过程如下图所示：

![](/images/kernel/20201109-11.png)

首先判断该数据包是否符合桥转发的条件：

  (1)桥端口状态是否是开启状态，如果没有开启则丢掉数据包

  (2)是否允许从该桥上转发，如果不允许，则直接返回0

获得桥转发的条件以后，开始判断数据包的类型：

  (1)判断此时桥的标志为允许做哪些事情，学习还是扩展

  如果学习的标志位被至位，则更新数据转发表。否则继续向下走

  (2)根据多播或者广播报文的类型决定数据包的去留

  (3)判断此时端口的状态，如果是学习状态，则将数据包丢弃

  (要注意的是：桥的端口状态(和上面的flag不冲突，上面的flag表示网桥可以做的事情)state表示网桥端口所处于的状态)
在处理完一些需要预备的事情之后，就要为数据包的转发开始做准备了

  (1)网桥设备是否处于混杂模式，如果是则建立副本，为发往本地做个备份

  (注意的是，所有网桥端口绑定的设备都会处于混杂模式，因为 网桥运行必须此模式。但除非明确的对其进行配置，否则网桥自己是不会处于混杂模式的)

  (2)在次判断广播还是多播地址

   广播地址：仅仅设置副本，进行广播转发和发往本地

多播地址：先查多播地址转发表，如果存在，设置副本，进行多播转发，原始数据包指向NULL,如果已经传送至本地，则会释放副本，不进行本地转发，否则重新转发到本地

  (3)不是广播或者多播

  判断是否本地地址，如果是本地地址，则将原始数据包指向NULL，发往本地。

  否则进行数据包转发

## 桥数据包转发

无论是在发往本地还是转发，有一个函数的功能是不能忽略的，就是br_handle_vlan函数
</code></pre>

<pre><code>struct sk_buff *br_handle_vlan(struct net_bridge *br,
                   struct net_bridge_vlan_group *vg,
                   struct sk_buff *skb)
{
    struct br_vlan_stats *stats;
    struct net_bridge_vlan *v;
    u16 vid;

    /* If this packet was not filtered at input, let it pass */
    if (!BR_INPUT_SKB_CB(skb)-&gt;vlan_filtered)
        goto out;

    /* At this point, we know that the frame was filtered and contains
     * a valid vlan id.  If the vlan id has untagged flag set,
     * send untagged; otherwise, send tagged.
     */
    br_vlan_get_tag(skb, &amp;vid);
    /*find vid from vlan group*/
    v = br_vlan_find(vg, vid);
    /* Vlan entry must be configured at this point.  The
     * only exception is the bridge is set in promisc mode and the
     * packet is destined for the bridge device.  In this case
     * pass the packet as is.
     */
    if (!v || !br_vlan_should_use(v)) {
        if ((br-&gt;dev-&gt;flags &amp; IFF_PROMISC) &amp;&amp; skb-&gt;dev == br-&gt;dev) {
            goto out;
        } else {
            kfree_skb(skb);
            return NULL;
        }
    }
    /*statistacs the vlan if flow and if the vlan_stats_enabled is true */
    if (br-&gt;vlan_stats_enabled) {
        stats = this_cpu_ptr(v-&gt;stats);
        u64_stats_update_begin(&amp;stats-&gt;syncp);
        stats-&gt;tx_bytes += skb-&gt;len;
        stats-&gt;tx_packets++;
        u64_stats_update_end(&amp;stats-&gt;syncp);
    }

    if (v-&gt;flags &amp; BRIDGE_VLAN_INFO_UNTAGGED)
        skb-&gt;vlan_tci = 0;
out:
    return skb;
}
</code></pre>

<pre><code>
这个函数的作用很简单就是，数据包是否要带tag,

过程：

在传递进来的vlan group中查找自己所处的vlan

如果该vlan不存在则判断当前模式是否是混杂模式和数据包的设备是否是桥下的设备，选择发包或者丢弃。

如果存在，且vlan是开启的，则统计vlan接口上的数据流量，最后根据vlan出口的标记位进行位运算判断是否要带tag.

然后我们来看一下上节提到的发往本地数据包的处理函数
</code></pre>

<pre><code>static int br_pass_frame_up(struct sk_buff *skb)
{
    struct net_device *indev, *brdev = BR_INPUT_SKB_CB(skb)-&gt;brdev;
    struct net_bridge *br = netdev_priv(brdev);
    struct net_bridge_vlan_group *vg;
    struct pcpu_sw_netstats *brstats = this_cpu_ptr(br-&gt;stats);
    /*统计该桥上的流量*/
    u64_stats_update_begin(&amp;brstats-&gt;syncp);
    brstats-&gt;rx_packets++;
    brstats-&gt;rx_bytes += skb-&gt;len;
    u64_stats_update_end(&amp;brstats-&gt;syncp);

    /*获取该桥上的vlan组*/
    vg = br_vlan_group_rcu(br);
    /* Bridge is just like any other port.  Make sure the
     * packet is allowed except in promisc modue when someone
     * may be running packet capture.
     */
    if (!(brdev-&gt;flags &amp; IFF_PROMISC) &amp;&amp;
        !br_allowed_egress(vg, skb)) {
        kfree_skb(skb);
        return NET_RX_DROP;
    }
    /*替换掉数据包中的设备信息改为桥设备*/
    indev = skb-&gt;dev;
    skb-&gt;dev = brdev;
    /*配置数据包vlan的相关信息*/
    skb = br_handle_vlan(br, vg, skb);
    if (!skb)
        return NET_RX_DROP;
    /*进入NF_BR_LOCAL_IN*/
    return NF_HOOK(NFPROTO_BRIDGE, NF_BR_LOCAL_IN,
               dev_net(indev), NULL, skb, indev, NULL,
               br_netif_receive_skb);
}
</code></pre>

<pre><code>
这个函数所做的事情很简单，就是配置vlan的相关信息后，然后发往本地的netfilter钩子函数中
最后重新回到netif_recive_skb.如下函数：
</code></pre>

<pre><code>static int
br_netif_receive_skb(struct net *net, struct sock *sk, struct sk_buff *skb)
{
    return netif_receive_skb(skb);
}
</code></pre>

<pre><code>
再来看看数据包转发的函数
</code></pre>

<pre><code>static void __br_forward(const struct net_bridge_port *to, struct sk_buff *skb)
{
    struct net_bridge_vlan_group *vg;
    struct net_device *indev;

    if (skb_warn_if_lro(skb)) {
        kfree_skb(skb);
        return;
    }
    /*获取vlan组，这个组中有许多的vlanid，br_handle_vlan函数就是要在这个组中查找自己的vid*/
    vg = nbp_vlan_group_rcu(to);
    /*添加vlan的相关配置*/
    skb = br_handle_vlan(to-&gt;br, vg, skb);
    if (!skb)
        return;

    indev = skb-&gt;dev;
    skb-&gt;dev = to-&gt;dev;
    skb_forward_csum(skb);

    NF_HOOK(NFPROTO_BRIDGE, NF_BR_FORWARD,
        dev_net(indev), NULL, skb, indev, skb-&gt;dev,
        br_forward_finish);
}

int br_forward_finish(struct net *net, struct sock *sk, struct sk_buff *skb)
{
    return NF_HOOK(NFPROTO_BRIDGE, NF_BR_POST_ROUTING,
               net, sk, skb, NULL, skb-&gt;dev,
               br_dev_queue_push_xmit);

}
</code></pre>

<p>```</p>

<p>整个数据包转发的过程与转发到本地的过程类似，只不过所进入的netfilter钩子点不同.</p>

<p>整个分析中不包含数据包从本地发出的数据包</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Linux 上的抽象网络设备]]></title>
    <link href="http://abcdxyzk.github.io/blog/2020/11/09/kernel-device/"/>
    <updated>2020-11-09T13:37:00+08:00</updated>
    <id>http://abcdxyzk.github.io/blog/2020/11/09/kernel-device</id>
    <content type="html"><![CDATA[<p><a href="https://www.ibm.com/developerworks/cn/linux/1310_xiawc_networkdevice/">https://www.ibm.com/developerworks/cn/linux/1310_xiawc_networkdevice/</a></p>

<p>和磁盘设备类似，Linux 用户想要使用网络功能，不能通过直接操作硬件完成，而需要直接或间接的操作一个 Linux 为我们抽象出来的设备，既通用的 Linux 网络设备来完成。一个常见的情况是，系统里装有一个硬件网卡，Linux 会在系统里为其生成一个网络设备实例，如 eth0，用户需要对 eth0 发出命令以配置或使用它了。更多的硬件会带来更多的设备实例，虚拟的硬件也会带来更多的设备实例。随着网络技术，虚拟化技术的发展，更多的高级网络设备被加入了到了 Linux 中，使得情况变得更加复杂。在以下章节中，将一一分析在虚拟化技术中经常使用的几种 Linux 网络设备抽象类型：Bridge、802.1.q VLAN device、VETH、TAP，详细解释如何用它们配合 Linux 中的 Route table、IP table 简单的创建出本地虚拟网络。
相关网络设备工作原理</p>

<h3>Bridge</h3>

<p> Bridge（桥）是 Linux 上用来做 TCP/IP 二层协议交换的设备，与现实世界中的交换机功能相似。Bridge 设备实例可以和 Linux 上其他网络设备实例连接，既 attach 一个从设备，类似于在现实世界中的交换机和一个用户终端之间连接一根网线。当有数据到达时，Bridge 会根据报文中的 MAC 信息进行广播、转发、丢弃处理。</p>

<p>图 1.Bridge 设备工作过程</p>

<p><img src="/images/kernel/20201109-1.jpg" alt="" /></p>

<p> 如图所示，Bridge 的功能主要在内核里实现。当一个从设备被 attach 到 Bridge 上时，相当于现实世界里交换机的端口被插入了一根连有终端的网线。这时在内核程序里，netdev_rx_handler_register()被调用，一个用于接受数据的回调函数被注册。以后每当这个从设备收到数据时都会调用这个函数可以把数据转发到 Bridge 上。当 Bridge 接收到此数据时，br_handle_frame()被调用，进行一个和现实世界中的交换机类似的处理过程：判断包的类别（广播/单点），查找内部 MAC 端口映射表，定位目标端口号，将数据转发到目标端口或丢弃，自动更新内部 MAC 端口映射表以自我学习。</p>

<p>Bridge 和现实世界中的二层交换机有一个区别，图中左侧画出了这种情况：数据被直接发到 Bridge 上，而不是从一个端口接受。这种情况可以看做 Bridge 自己有一个 MAC 可以主动发送报文，或者说 Bridge 自带了一个隐藏端口和寄主 Linux 系统自动连接，Linux 上的程序可以直接从这个端口向 Bridge 上的其他端口发数据。所以当一个 Bridge 拥有一个网络设备时，如 bridge0 加入了 eth0 时，实际上 bridge0 拥有两个有效 MAC 地址，一个是 bridge0 的，一个是 eth0 的，他们之间可以通讯。由此带来一个有意思的事情是，Bridge 可以设置 IP 地址。通常来说 IP 地址是三层协议的内容，不应该出现在二层设备 Bridge 上。但是 Linux 里 Bridge 是通用网络设备抽象的一种，只要是网络设备就能够设定 IP 地址。当一个 bridge0 拥有 IP 后，Linux 便可以通过路由表或者 IP 表规则在三层定位 bridge0，此时相当于 Linux 拥有了另外一个隐藏的虚拟网卡和 Bridge 的隐藏端口相连，这个网卡就是名为 bridge0 的通用网络设备，IP 可以看成是这个网卡的。当有符合此 IP 的数据到达 bridge0 时，内核协议栈认为收到了一包目标为本机的数据，此时应用程序可以通过 Socket 接收到它。一个更好的对比例子是现实世界中的带路由的交换机设备，它也拥有一个隐藏的 MAC 地址，供设备中的三层协议处理程序和管理程序使用。设备里的三层协议处理程序，对应名为 bridge0 的通用网络设备的三层协议处理程序，即寄主 Linux 系统内核协议栈程序。设备里的管理程序，对应 bridge0 寄主 Linux 系统里的应用程序。</p>

<p>Bridge 的实现当前有一个限制：当一个设备被 attach 到 Bridge 上时，那个设备的 IP 会变的无效，Linux 不再使用那个 IP 在三层接受数据。举例如下：如果 eth0 本来的 IP 是 192.168.1.2，此时如果收到一个目标地址是 192.168.1.2 的数据，Linux 的应用程序能通过 Socket 操作接受到它。而当 eth0 被 attach 到一个 bridge0 时，尽管 eth0 的 IP 还在，但应用程序是无法接受到上述数据的。此时应该把 IP 192.168.1.2 赋予 bridge0。</p>

<p>另外需要注意的是数据流的方向。对于一个被 attach 到 Bridge 上的设备来说，只有它收到数据时，此包数据才会被转发到 Bridge 上，进而完成查表广播等后续操作。当请求是发送类型时，数据是不会被转发到 Bridge 上的，它会寻找下一个发送出口。用户在配置网络时经常忽略这一点从而造成网络故障。</p>

<h3>VLAN device for 802.1.q</h3>

<p>VLAN 又称虚拟网络，是一个被广泛使用的概念，有些应用程序把自己的内部网络也称为 VLAN。此处主要说的是在物理世界中存在的，需要协议支持的 VLAN。它的种类很多，按照协议原理一般分为：MACVLAN、802.1.q VLAN、802.1.qbg VLAN、802.1.qbh VLAN。其中出现较早，应用广泛并且比较成熟的是 802.1.q VLAN，其基本原理是在二层协议里插入额外的 VLAN 协议数据（称为 802.1.q VLAN Tag)，同时保持和传统二层设备的兼容性。Linux 里的 VLAN 设备是对 802.1.q 协议的一种内部软件实现，模拟现实世界中的 802.1.q 交换机。</p>

<p>图 2 .VLAN 设备工作过程</p>

<p><img src="/images/kernel/20201109-2.jpg" alt="" /></p>

<p>如图所示，Linux 里 802.1.q VLAN 设备是以母子关系成对出现的，母设备相当于现实世界中的交换机 TRUNK 口，用于连接上级网络，子设备相当于普通接口用于连接下级网络。当数据在母子设备间传递时，内核将会根据 802.1.q VLAN Tag 进行对应操作。母子设备之间是一对多的关系，一个母设备可以有多个子设备，一个子设备只有一个母设备。当一个子设备有一包数据需要发送时，数据将被加入 VLAN Tag 然后从母设备发送出去。当母设备收到一包数据时，它将会分析其中的 VLAN Tag，如果有对应的子设备存在，则把数据转发到那个子设备上并根据设置移除 VLAN Tag，否则丢弃该数据。在某些设置下，VLAN Tag 可以不被移除以满足某些监听程序的需要，如 DHCP 服务程序。举例说明如下：eth0 作为母设备创建一个 ID 为 100 的子设备 eth0.100。此时如果有程序要求从 eth0.100 发送一包数据，数据将被打上 VLAN 100 的 Tag 从 eth0 发送出去。如果 eth0 收到一包数据，VLAN Tag 是 100，数据将被转发到 eth0.100 上，并根据设置决定是否移除 VLAN Tag。如果 eth0 收到一包包含 VLAN Tag 101 的数据，其将被丢弃。上述过程隐含以下事实：对于寄主 Linux 系统来说，母设备只能用来收数据，子设备只能用来发送数据。和 Bridge 一样，母子设备的数据也是有方向的，子设备收到的数据不会进入母设备，同样母设备上请求发送的数据不会被转到子设备上。可以把 VLAN 母子设备作为一个整体想象为现实世界中的 802.1.q 交换机，下级接口通过子设备连接到寄主 Linux 系统网络里，上级接口同过主设备连接到上级网络，当母设备是物理网卡时上级网络是外界真实网络，当母设备是另外一个 Linux 虚拟网络设备时上级网络仍然是寄主 Linux 系统网络。</p>

<p>需要注意的是母子 VLAN 设备拥有相同的 MAC 地址，可以把它当成现实世界中 802.1.q 交换机的 MAC，因此多个 VLAN 设备会共享一个 MAC。当一个母设备拥有多个 VLAN 子设备时，子设备之间是隔离的，不存在 Bridge 那样的交换转发关系，原因如下：802.1.q VLAN 协议的主要目的是从逻辑上隔离子网。现实世界中的 802.1.q 交换机存在多个 VLAN，每个 VLAN 拥有多个端口，同一 VLAN 端口之间可以交换转发，不同 VLAN 端口之间隔离，所以其包含两层功能：交换与隔离。Linux VLAN device 实现的是隔离功能，没有交换功能。一个 VLAN 母设备不可能拥有两个相同 ID 的 VLAN 子设备，因此也就不可能出现数据交换情况。如果想让一个 VLAN 里接多个设备，就需要交换功能。在 Linux 里 Bridge 专门实现交换功能，因此将 VLAN 子设备 attach 到一个 Bridge 上就能完成后续的交换功能。总结起来，Bridge 加 VLAN device 能在功能层面完整模拟现实世界里的 802.1.q 交换机。</p>

<p>Linux 支持 VLAN 硬件加速，在安装有特定硬件情况下，图中所述内核处理过程可以被放到物理设备上完成。</p>

<h3>TAP 设备与 VETH 设备</h3>

<p>TUN/TAP 设备是一种让用户态程序向内核协议栈注入数据的设备，一个工作在三层，一个工作在二层，使用较多的是 TAP 设备。VETH 设备出现较早，它的作用是反转通讯数据的方向，需要发送的数据会被转换成需要收到的数据重新送入内核网络层进行处理，从而间接的完成数据的注入。</p>

<p>图 3 .TAP 设备和 VETH 设备工作过程</p>

<p><img src="/images/kernel/20201109-3.jpg" alt="" /></p>

<p>如图所示，当一个 TAP 设备被创建时，在 Linux 设备文件目录下将会生成一个对应 char 设备，用户程序可以像打开普通文件一样打开这个文件进行读写。当执行 write()操作时，数据进入 TAP 设备，此时对于 Linux 网络层来说，相当于 TAP 设备收到了一包数据，请求内核接受它，如同普通的物理网卡从外界收到一包数据一样，不同的是其实数据来自 Linux 上的一个用户程序。Linux 收到此数据后将根据网络配置进行后续处理，从而完成了用户程序向 Linux 内核网络层注入数据的功能。当用户程序执行 read()请求时，相当于向内核查询 TAP 设备上是否有需要被发送出去的数据，有的话取出到用户程序里，完成 TAP 设备的发送数据功能。针对 TAP 设备的一个形象的比喻是：使用 TAP 设备的应用程序相当于另外一台计算机，TAP 设备是本机的一个网卡，他们之间相互连接。应用程序通过 read()/write()操作，和本机网络核心进行通讯。</p>

<p>VETH 设备总是成对出现，送到一端请求发送的数据总是从另一端以请求接受的形式出现。该设备不能被用户程序直接操作，但使用起来比较简单。创建并配置正确后，向其一端输入数据，VETH 会改变数据的方向并将其送入内核网络核心，完成数据的注入。在另一端能读到此数据。</p>

<h3>网络设置举例说明</h3>

<p>为了更好的说明 Linux 网络设备的用法，下面将用一系列的例子，说明在一个复杂的 Linux 网络元素组合出的虚拟网络里，数据的流向。网络设置简介如下：一个中心 Bridge：bridge0 下 attach 了 4 个网络设备，包括 2 个 VETH 设备，1 个 TAP 设备 tap0，1 个物理网卡 eth0。在 VETH 的另外一端又创建了 VLAN 子设备。Linux 上共存在 2 个 VLAN 网络，既 vlan100 与 vlan200。物理网卡和外部网络相连，并且在它之下创建了一个 VLAN ID 为 200 的 VLAN 子设备。</p>

<h4>从 vlan100 子设备发送 ARP 报文</h4>

<p>图 4 .ARP from vlan100 child device</p>

<p><img src="/images/kernel/20201109-4.jpg" alt="" /></p>

<p>如图所示，当用户尝试 ping 192.168.100.3 时，Linux 将会根据路由表，从 vlan100 子设备发出 ARP 报文，具体过程如下：</p>

<p>1) 用户 ping 192.168.100.3</p>

<p>2) Linux 向 vlan100 子设备发送 ARP 信息。</p>

<p>3) ARP 报文被打上 VLAN ID 100 的 Tag 成为 ARP@vlan100，转发到母设备上。</p>

<p>4) VETH 设备将这一发送请求转变方向，成为一个需要接受处理的报文送入内核网络模块。</p>

<p>5) 由于对端的 VETH 设备被加入到了 bridge0 上，并且内核发现它收到一个报文，于是报文被转发到 bridge0 上。</p>

<p>6) bridge0 处理此 ARP@vlan100 信息，根据 TCP/IP 二层协议发现是一个广播请求，于是向它所知道的所有端口广播此报文，其中一路进入另一对 VETH 设备的一端，一路进入 TAP 设备 tap0，一路进入物理网卡设备 eth0。此时在 tap0 上，用户程序可以通过 read()操作读到 ARP@vlan100，eth0 将会向外界发送 ARP@vlan100，但 eth0 的 VLAN 子设备不会收到它，因为此数据方向为请求发送而不是请求接收。</p>

<p>7) VETH 将请求方向转换，此时在另一端得到请求接受的 ARP@vlan100 报文。</p>

<p>8) 对端 VETH 设备发现有数据需要接受，并且自己有两个 VLAN 子设备，于是执行 VLAN 处理逻辑。其中一个子设备是 vlan100，与 ARP@vlan100 吻合，于是去除 VLAN ID 100 的 Tag 转发到这个子设备上，重新成为标准的以太网 ARP 报文。另一个子设备由于 ID 不吻合，不会得到此报文。</p>

<p>9) 此 VLAN 子设备又被 attach 到另一个桥 bridge1 上，于是转发自己收到的 ARP 报文。</p>

<p>10) bridge1 广播 ARP 报文。</p>

<p>11) 最终另外一个 TAP 设备 tap1 收到此请求发送报文，用户程序通过 read()可以得到它。</p>

<h4>从 vlan200 子设备发送 ARP 报文</h4>

<p>图 5 .ARP from vlan200 child device</p>

<p><img src="/images/kernel/20201109-5.jpg" alt="" /></p>

<p>和前面情况类似，区别是 VLAN ID 是 200，对端的 vlan200 子设备设置为 reorder_hdr = 0，表示此设备被要求保留收到的报文中的 VLAN Tag。此时子设备会收到 ARP 报文，但是带了 VLAN ID 200 的 Tag，既 ARP@vlan200。</p>

<h4>从中心 bridge 发送 ARP 报文</h4>

<p>图 5 .ARP from central bridge</p>

<p><img src="/images/kernel/20201109-6.jpg" alt="" /></p>

<p>当 bridge0 拥有 IP 时，通过 Linux 路由表用户程序可以直接将 ARP 报文发向 bridge0。这时 tap0 和外部网络都能收到 ARP，但 VLAN 子设备由于 VLAN ID 过滤的原因，将收不到 ARP 信息。</p>

<h4>从外部网络向物理网卡发送 ARP@vlan200 报文</h4>

<p>图 6 .ARP from external network</p>

<p><img src="/images/kernel/20201109-7.jpg" alt="" /></p>

<p>当外部网络连接在一个支持 VLAN 并且对应端口为 vlan200 时，此情况会发生。此时所有的 VLAN ID 为 200 的 VLAN 子设备都将接受到报文，如果设置 reorder_hdr=0 则会收到带 Tag 的 ARP@vlan200。</p>

<h4>从 TAP 设备以 ping 方式发送 ARP</h4>

<p>图 7 .ping from TAP device</p>

<p><img src="/images/kernel/20201109-8.jpg" alt="" /></p>

<p>给 tap0 赋予 IP 并加入路由，此时再 Ping 其对应网段的未知 IP 会产生 ARP 发送请求。需要注意的是此时由于 tap0 上存在的是发送而不是接收请求，因此 ARP 报文不会被转发到桥上，从而什么也不会发生。图中右边画了一个类似情况：从 vlan200 子设备发送 ARP 请求。由于缺少 VETH 设备反转请求方向，因此报文也不会被转发到桥上，而是直接通过物理网卡发往外部网络。</p>

<h4>以文件操作方式从 TAP 设备发送报文</h4>

<p>图 8 .file operation on TAP device</p>

<p><img src="/images/kernel/20201109-9.jpg" alt="" /></p>

<p>用户程序指定 tap0 设备发送报文有两种方式：socket 和 file operation。当用 socket_raw 标志新建 socket 并指定设备编号时，可以要求内核将报文从 tap0 发送。但和前面的 ping from tap0 情况类似，由于报文方向问题，消息并不会被转发到 bridge0 上。当用 open()方式打开 tap 设备文件时，情况有所不同。当执行 write()操作时，内核认为 tap0 收到了报文，从而会触发转发动作，bridge0 将收到它。如果发送的报文如图所示，是一个以 A 为目的地的携带 VLAN ID 100 Tag 的单点报文，bridge0 将会找到对应的设备进行转发，对应的 VLAN 子设备将收到没有 VLAN ID 100 Tag 的报文。
Linux 上配置网络设备命令举例</p>

<p>以 Redhat6.2 红帽 Linux 发行版为例，如果已安装 VLAN 内核模块和管理工具 vconfig，TAP/TUN 设备管理工具 tunctl，那么可以用以下命令设置前述网络设备：</p>

<pre><code>        创建 Bridge：brctl addbr [BRIDGE NAME]
        删除 Bridge：brctl delbr [BRIDGE NAME]
        attach 设备到 Bridge：brctl addif [BRIDGE NAME] [DEVICE NAME]
        从 Bridge detach 设备：brctl delif [BRIDGE NAME] [DEVICE NAME]
        查询 Bridge 情况：brctl show
        创建 VLAN 设备：vconfig add [PARENT DEVICE NAME] [VLAN ID]
        删除 VLAN 设备：vconfig rem [VLAN DEVICE NAME]
        设置 VLAN 设备 flag：vconfig set_flag [VLAN DEVICE NAME] [FLAG] [VALUE]
        设置 VLAN 设备 qos：

    vconfig set_egress_map [VLAN DEVICE NAME] [SKB_PRIORITY] [VLAN_QOS]

    vconfig set_ingress_map [VLAN DEVICE NAME] [SKB_PRIORITY] [VLAN_QOS]

        查询 VLAN 设备情况：cat /proc/net/vlan/[VLAN DEVICE NAME]
        创建 VETH 设备：ip link add link [DEVICE NAME] type veth
        创建 TAP 设备：tunctl -p [TAP DEVICE NAME]
        删除 TAP 设备：tunctl -d [TAP DEVICE NAME]
        查询系统里所有二层设备，包括 VETH/TAP 设备：ip link show
        删除普通二层设备：ip link delete [DEVICE NAME] type [TYPE]
</code></pre>
]]></content>
  </entry>
  
</feed>
