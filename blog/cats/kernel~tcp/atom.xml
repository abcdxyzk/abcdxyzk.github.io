<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: kernel~tcp | kk Blog —— 通用基础]]></title>
  <link href="http://abcdxyzk.github.io/blog/cats/kernel~tcp/atom.xml" rel="self"/>
  <link href="http://abcdxyzk.github.io/"/>
  <updated>2024-12-31T15:33:01+08:00</updated>
  <id>http://abcdxyzk.github.io/</id>
  <author>
    <name><![CDATA[kk]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[seq_file]]></title>
    <link href="http://abcdxyzk.github.io/blog/2020/10/12/seq_file/"/>
    <updated>2020-10-12T19:07:00+08:00</updated>
    <id>http://abcdxyzk.github.io/blog/2020/10/12/seq_file</id>
    <content type="html"><![CDATA[<p><a href="https://www.cnblogs.com/Wandererzj/archive/2012/04/16/2452209.html">https://www.cnblogs.com/Wandererzj/archive/2012/04/16/2452209.html</a></p>

<pre><code>    struct seq_operations {
        void * (*start) (struct seq_file *m, loff_t *pos);
        void (*stop) (struct seq_file *m, void *v);
        void * (*next) (struct seq_file *m, void *v, loff_t *pos);
        int (*show) (struct seq_file *m, void *v);
    };
</code></pre>

<h4>seq_open</h4>

<pre><code>int seq_open(struct file *file, const struct seq_operations *op)
{
    struct seq_file *p = file-&gt;private_data;

    if (!p) {
        p = kmalloc(sizeof(*p), GFP_KERNEL);
        if (!p)
            return -ENOMEM;
        file-&gt;private_data = p;
    }
    memset(p, 0, sizeof(*p));
    mutex_init(&amp;p-&gt;lock);
    p-&gt;op = op;

    file-&gt;f_version = 0;

    file-&gt;f_mode &amp;= ~FMODE_PWRITE;
    return 0;
}
</code></pre>

<h4>seq_read 读取过程</h4>

<p>正常情况下分两次完成：</p>

<p>第一次执行执行seq_read时：start->show->next->show&hellip;->next->show->next->stop，此时返回内核自定义缓冲区所有内容，即copied !=0,所以会有第二次读取操作</p>

<p>第二次执行seq_read时：由于此时内核自定义内容都返回，根据seq_file->index指示，所以执行start->stop，返回0，即copied=0，并退出seq_read操作</p>

<pre><code>    ssize_t seq_read(struct file *file, char __user *buf, size_t size, loff_t *ppos)
    {
        struct seq_file *m = (struct seq_file *)file-&gt;private_data;
        size_t copied = 0;
        loff_t pos;
        size_t n;
        void *p;
        int err = 0;

        mutex_lock(&amp;m-&gt;lock);

        ...

        /* we need at least one record in buffer */
        pos = m-&gt;index;
        p = m-&gt;op-&gt;start(m, &amp;pos);
        while (1)
        {
            err = PTR_ERR(p);
            if (!p || IS_ERR(p))
                break;
            err = m-&gt;op-&gt;show(m, p);

            if (err &lt; 0)
                break;
            if (unlikely(err))
                m-&gt;count = 0;
            if (unlikely(!m-&gt;count)) {
                p = m-&gt;op-&gt;next(m, p, &amp;pos);
                m-&gt;index = pos;
                continue;
            }

            if (m-&gt;count &lt; m-&gt;size)
                goto Fill;
            m-&gt;op-&gt;stop(m, p);
            kfree(m-&gt;buf);
            m-&gt;buf = kmalloc(m-&gt;size &lt;&lt;= 1, GFP_KERNEL);
            if (!m-&gt;buf)
                goto Enomem;
            m-&gt;count = 0;
            m-&gt;version = 0;
            pos = m-&gt;index;
            p = m-&gt;op-&gt;start(m, &amp;pos);
        }
        m-&gt;op-&gt;stop(m, p);
        m-&gt;count = 0;
        goto Done;
    Fill:
        /* they want more? let's try to get some more */
        while (m-&gt;count &lt; size) {
            size_t offs = m-&gt;count;
            loff_t next = pos;
            p = m-&gt;op-&gt;next(m, p, &amp;next);
            if (!p || IS_ERR(p)) {
                err = PTR_ERR(p);
                break;
            }
            err = m-&gt;op-&gt;show(m, p);
            if (m-&gt;count == m-&gt;size || err) {
                m-&gt;count = offs;
                if (likely(err &lt;= 0))
                    break;
            }
            pos = next;
        }
        m-&gt;op-&gt;stop(m, p);
        n = min(m-&gt;count, size);
        err = copy_to_user(buf, m-&gt;buf, n);
        if (err)
            goto Efault;
        copied += n;
        m-&gt;count -= n;
        if (m-&gt;count)
            m-&gt;from = n;
        else
            pos++;
        m-&gt;index = pos;
    Done:
        if (!copied)
            copied = err;   //copied = 0
        else {
            *ppos += copied;
            m-&gt;read_pos += copied;
        }
        file-&gt;f_version = m-&gt;version;
        mutex_unlock(&amp;m-&gt;lock);
        return copied;
    Enomem:
        err = -ENOMEM;
        goto Done;
    Efault:
        err = -EFAULT;
        goto Done;
    }
</code></pre>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[hybrid slow start 混合慢启动算法]]></title>
    <link href="http://abcdxyzk.github.io/blog/2020/10/12/slow-start/"/>
    <updated>2020-10-12T13:37:00+08:00</updated>
    <id>http://abcdxyzk.github.io/blog/2020/10/12/slow-start</id>
    <content type="html"><![CDATA[<p><a href="https://www.jianshu.com/p/f2edbaca4f2c">https://www.jianshu.com/p/f2edbaca4f2c</a></p>

<p>传统的单纯采用指数增长的慢启动算法有一个无法避免的问题，在临界进入拥塞避免阶段时，特别是在高带宽长距离网络中，容易出现大规模丢包，进而导致大量数据包重传，也有可能出现timeout，致使网络带宽利用率下降。</p>

<p>Hybrid Slow Start，它在传统的慢启动算法中加入了判断机制，强制从慢启动转入拥塞避免。这里主要说说其在CUBIC中是怎么实现的。</p>

<h3>变量介绍</h3>

<pre><code>    #define HYSTART_ACK_TRAIN      0x1 //进入拥塞避免的条件
    #define HYSTART_DELAY          0x2 //进入拥塞避免的条件
    #define HYSTART_MIN_SAMPLES    8   //表示至少取一个RTT的前8个ACK作为样本
    #define HYSTART_DELAY_MIN      (4u&lt;&lt;3) 
    #define HYSTART_DELAY_MAX      (16u&lt;&lt;3)
    /* if x &gt; HYSTART_DELAY_MAX，return HYSTART_DELAY_MAX 
     * else if x &lt; HYSTART_DELAY_MIN，return HYATART_DELAY_MIN
     * else return x
     */
    #define HYSTART_DELAY_THRESH clamp(x, HYSTART_DELAY_MIN, HYSTART_DELAY_MAX)
    static int hystart __read_mostly = 1;
    static int hystart_detect __read_mostly = HYSTART_ACK_TRAIN | HYSART_DELAY;
    static int hystart_low_window __read_mostly = 16;
    static int hystart_ack_delta __read_mostly = 2;

    struct bictcp {
        ...
        u32    delay_min;   //全局最小rtt
        u32    round_start; //记录慢启动的起始时间
        u32    curr_rtt;    //记录样本中的最小rtt
        u8      found;
        u8      sample_cnt; //样本计数变量
        ...
    };
</code></pre>

<h3>两类退出slow start机制</h3>

<p>在Hybrid Slow Start算法中给出了种类判断机制用来退出慢启动进入拥塞避免，分别是ACKs train length和Increase in packet delays。</p>

<h4>ACKS train length</h4>

<p>这里给出一段原文描述，在这段描述中说了怎么测ACKs train length以及为什么要用ACKs train length。</p>

<p>The ACK train length is measured by calculating the sum of inter-arrival times of all the closely spaced ACKs within an RTT round. The train length is strongly affected by the bottleneck bandwidth, routing delays and buffer sizes along the path, and is easily stretched out by congestion caused by cross traffic in the path, so by estimating the train length we can reliably find a safe exit point of Slow Start.</p>

<h4>Increase in packet delays</h4>

<p>同样还是一段原文描述，如果你问我为什么不直接翻译成中文，我不会回答你这个问题的。</p>

<p>Increase in packet delays during Slow Start may indicate the possibility of the bottleneck router being congested.</p>

<p>但是Increase in packet delays的测量会受到bursty transmission的影响，所以只测一个RTT中刚开始的几个数据包的往返时间来避免bursty transission的影响，在后面给出的code中会看到</p>

<h3>函数实现</h3>

<p>hystart重置函数</p>

<pre><code>    static inline void bictcp_hystart_reset(struct sock *sk)
    {
        struct tcp_sock *tp = tcp_sk(sk);
        struct bictcp *ca = inet_csk_ca(sk);

        ca-&gt;round_start = ca-&gt;last_ack = bictcp_clock(); //记录慢启动的开始时间
        ca-&gt;end_seq = tp-&gt;snd_nxt;
        ca-&gt;curr_rtt = 0;   //重置样本最小rtt为0
        ca-&gt;sample_cnt = 0; //重置样本计数为0
    }
</code></pre>

<p>Hybrid Slow Start实现的核心部分</p>

<pre><code>    static void hystart_update(struct sock *sk, u32 delay)
    {
        struct tcp_sock *tp = tcp_sk(sk);
        struct bictcp *ca = inet_csk_ca(sk);

        //如果ca-&gt;found &amp; hystart_detect为真，表示应该进入拥塞避免
        if (!(ca-&gt;found &amp; hystart_detect)) {
            u32 now = bictcp_clock(); //获取当前时间

            /* first detection parameter - ack-train detection */
            /* 前后到来的两个ACK的间隔时间小于hystart_ack_delta才有效 */
            if ((s32)(now - ca-&gt;last_ack) &lt;= hystart_ack_delta) {
                ca-&gt;last_ack = now;  //更新上一个ACK到来的时间
                /* 每次慢启动时会重置round_start为0，结合前面的if条件，下面的
                 * if成立的条件是：从慢启动开始到现在经过的时间如果大于
                 * delay_min&gt;&gt;4，那么可以进入拥塞避免了。至于为什么选
                 * delay_min&gt;&gt;4这个值，鬼知道。
                 */
                if ((s32)(now - ca-&gt;round_start) &gt; ca-&gt;delay_min &gt;&gt; 4)
                    ca-&gt;found |= HYSTART_ACK_TRAIN;
            }   

            /* obtain the minimum delay of more than sampling packets */
            /* 如果样本计数小于HYSTART_MIN_SAMPLES(默认为8) */
            if (ca-&gt;sample_cnt &lt; HYSTART_MIN_SAMPLES) {
                if (ca-&gt;curr_rtt == 0 || ca-&gt;curr_rtt &gt; delay)
                    ca-&gt;curr_rtt = delay;/* 更新样本中的最小rtt */

                ca-&gt;sample_cnt++;
            } else {//如果样本大于8了，那么就可以判断是否要进入拥塞避免了
                /* 如果前面8个样本中的最小rtt大于全局最小rtt与阈值的和，那么表示网络出
                 * 现了拥塞，应立马进入拥塞避免阶段，HYSTART_DELAY_THRESH()的返
                 * 回值在前面的变量介绍中有说明。
                if (ca-&gt;curr_rtt &gt; ca-&gt;delay_min +
                    HYSTART_DELAY_THRESH(ca-&gt;delay_min&gt;&gt;4))
                    ca-&gt;found |= HYSTART_DELAY;
            }   
            /*  
             * Either one of two conditions are met,
             * we exit from slow start immediately.
             */
            /* 如果为真就进入拥塞避免 */
            if (ca-&gt;found &amp; hystart_detect)
                tp-&gt;snd_ssthresh = tp-&gt;snd_cwnd;
        }   
    }
</code></pre>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Web压力测试工具]]></title>
    <link href="http://abcdxyzk.github.io/blog/2015/12/27/kernel-net-test-tool/"/>
    <updated>2015-12-27T02:51:00+08:00</updated>
    <id>http://abcdxyzk.github.io/blog/2015/12/27/kernel-net-test-tool</id>
    <content type="html"><![CDATA[<h4>curl wget 不验证证书进行https请求</h4>

<p> wget &lsquo;<a href="https://x.x.x.x/get_ips">https://x.x.x.x/get_ips</a>&rsquo; &ndash;no-check-certificate</p>

<p>curl &lsquo;<a href="https://x.x.x.x/get_ips">https://x.x.x.x/get_ips</a>&rsquo; -k</p>

<hr />

<p><a href="https://blog.csdn.net/hqzxsc2006/article/details/50547684">https://blog.csdn.net/hqzxsc2006/article/details/50547684</a></p>

<h4>通过curl得到http各阶段的响应时间</h4>

<p>url_effective The URL that was fetched last. This is most meaningful if you&rsquo;ve told curl to follow location: headers.</p>

<p>filename_effective The ultimate filename that curl writes out to. This is only meaningful if curl is told to write to a file with the &ndash;remote-name or &ndash;output option. It&rsquo;s most useful in combination with the &ndash;remote-header-name option. (Added in 7.25.1)</p>

<p>http_code http状态码，如200成功,301转向,404未找到,500服务器错误等。(The numerical response code that was found in the last retrieved HTTP(S) or FTP(s) transfer. In 7.18.2 the alias response_code was added to show the same info.)</p>

<p>http_connect The numerical code that was found in the last response (from a proxy) to a curl CONNECT request. (Added in 7.12.4)</p>

<p>time_total 总时间，按秒计。精确到小数点后三位。 （The total time, in seconds, that the full operation lasted. The time will be displayed with millisecond resolution.）</p>

<p>time_namelookup DNS解析时间,从请求开始到DNS解析完毕所用时间。(The time, in seconds, it took from the start until the name resolving was completed.)</p>

<p>time_connect 连接时间,从开始到建立TCP连接完成所用时间,包括前边DNS解析时间，如果需要单纯的得到连接时间，用这个time_connect时间减去前边time_namelookup时间。以下同理，不再赘述。(The time, in seconds, it took from the start until the TCP connect to the remote host (or proxy) was completed.)</p>

<p>time_appconnect 连接建立完成时间，如SSL/SSH等建立连接或者完成三次握手时间。(The time, in seconds, it took from the start until the SSL/SSH/etc connect/handshake to the remote host was completed. (Added in 7.19.0))</p>

<p>time_pretransfer 从开始到准备传输的时间。(The time, in seconds, it took from the start until the file transfer was just about to begin. This includes all pre-transfer commands and negotiations that are specific to the particular protocol(s) involved.)</p>

<p>time_redirect 重定向时间，包括到最后一次传输前的几次重定向的DNS解析，连接，预传输，传输时间。(The time, in seconds, it took for all redirection steps include name lookup, connect, pretransfer and transfer before the final transaction was started. time_redirect shows the complete execution time for multiple redirections. (Added in 7.12.3))</p>

<p>time_starttransfer 开始传输时间。在client发出请求之后，Web 服务器返回数据的第一个字节所用的时间(The time, in seconds, it took from the start until the first byte was just about to be transferred. This includes time_pretransfer and also the time the server needed to calculate the result.)</p>

<p>size_download 下载大小。(The total amount of bytes that were downloaded.)</p>

<p>size_upload 上传大小。(The total amount of bytes that were uploaded.)</p>

<p>size_header  下载的header的大小(The total amount of bytes of the downloaded headers.)</p>

<p>size_request 请求的大小。(The total amount of bytes that were sent in the HTTP request.)</p>

<p>speed_download 下载速度，单位-字节每秒。(The average download speed that curl measured for the complete download. Bytes per second.)</p>

<p>speed_upload 上传速度,单位-字节每秒。(The average upload speed that curl measured for the complete upload. Bytes per second.)</p>

<p>content_type 就是content-Type，不用多说了，这是一个访问我博客首页返回的结果示例(text/html; charset=UTF-8)；(The Content-Type of the requested document, if there was any.)</p>

<p>num_connects Number of new connects made in the recent transfer. (Added in 7.12.3)</p>

<p>num_redirects Number of redirects that were followed in the request. (Added in 7.12.3)</p>

<p>redirect_url When a HTTP request was made without -L to follow redirects, this variable will show the actual URL a redirect would take you to. (Added in 7.18.2)</p>

<p>ftp_entry_path The initial path libcurl ended up in when logging on to the remote FTP server. (Added in 7.15.4)</p>

<p>ssl_verify_result ssl认证结果，返回0表示认证成功。( The result of the SSL peer certificate verification that was requested. 0 means the verification was successful. (Added in 7.19.0))</p>

<p>1、可以直接访问使用：</p>

<pre><code>    curl -o /dev/null -s -w %{http_code}:%{http_connect}:%{content_type}:%{time_namelookup}:%{time_redirect}:%{time_pretransfer}:%{time_connect}:%{time_starttransfer}:%{time_total}:%{speed_download} www.baidu.com
</code></pre>

<p>输出变量需要按照%{variable_name}的格式，如果需要输出%，double一下即可，即%%，同时，\n是换行，\r是回车，\t是TAB。</p>

<p>-w 指定格式化文件</p>

<p>-o 请求重定向到,不带此参数则控制台输出返回结果</p>

<p>-s 静默，不显示进度</p>

<p>2、也可以定义时间格式化文件访问</p>

<pre><code>    #vim  curl-time.txt 
    \n
                  http: %{http_code}\n
                   dns: %{time_namelookup}s\n
              redirect: %{time_redirect}s\n
          time_connect: %{time_connect}s\n
       time_appconnect: %{time_appconnect}s\n
      time_pretransfer: %{time_pretransfer}s\n
    time_starttransfer: %{time_starttransfer}s\n
         size_download: %{size_download}bytes\n
        speed_download: %{speed_download}B/s\n
                      ----------\n
            time_total: %{time_total}s\n
    \n
</code></pre>

<pre><code>    curl -w "@curl_time.txt"  -s  -H "Content-Type: application/json" --insecure --header 'Host: passport.500.com' --data '{"platform":"android","userimei":"F5D815EA2BD8DBARD","app_channel":"10000","mbimei":"9DB358AF","version":"3.1.4","username":"hqzx","userpass":"976af4"}' --compressed https://119.147.113.177/user/login
</code></pre>

<hr />

<p><a href="http://297020555.blog.51cto.com/1396304/592386">http://297020555.blog.51cto.com/1396304/592386</a></p>

<pre><code>    */1 * * * * cd /root/test ; ./curl.sh &gt; /dev/null 2&gt;&amp;1
    */1 * * * * cd /root/test ; ./ping.sh &gt; /dev/null 2&gt;&amp;1

    curl.sh:
    if ps aux | grep curl | grep "30M" &gt; /dev/null ; then
        echo "..." &gt; /dev/null
    else
        ./curl_1.sh &amp;
        ./curl_2.sh &amp;
    fi

    curl_1.sh &amp; curl_2.sh:
    URL=192.168.1.3:80/30M
    T=`date "+%F %T"`
    curl $URL -s -o /tmp/df -w "$T %{time_connect} %{time_starttransfer} %{time_total} %{speed_download} %{http_code}\n" &gt;&gt; t_down

    ping.sh:
    date "+%F %T" &gt;&gt; ping_out
    ping -q -f -c 1000 192.168.1.3 &gt;&gt; ping_out
</code></pre>

<p>res.sh:
```
    #sed -i -e &lsquo;:a;N;$!ba;s/(:..)\n/\1 /g&rsquo; t_down
    cat ping_out | grep -E &ldquo;-|loss&rdquo; | grep -v statistics > ping_tmp
    sed -i -e &lsquo;:a;N;$!ba;s/(:..)\n/\1 /g&rsquo; ping_tmp</p>

<pre><code>python res.py &gt; res_out
python res2.py
</code></pre>

<pre><code>
统计结果和ping汇聚 res.py:
</code></pre>

<pre><code>import time

ff = open('t1_down').readlines()
qq = open('t2_down').readlines()
ping = open('ping_tmp').readlines()

j = 0
for i in range(0, len(ff)):
    f = ff[i].strip().split(' ')
    q = qq[i].strip().split(' ')

    if (len(f) != len(q)):
        break

    timeArray = time.strptime(f[0]+" "+f[1], "%Y-%m-%d %H:%M:%S")
    ft = time.mktime(timeArray)

    if (i &lt; len(ff) - 1):
        fn = ff[i+1].strip().split(' ')
        fnt = time.mktime(time.strptime(fn[0] + " " + fn[1], "%Y-%m-%d %H:%M:%S"))
    else:
        fnt = time.mktime(time.strptime("2020-01-01 00:00:00", "%Y-%m-%d %H:%M:%S"))

    po = "0"
    while (j &lt; len(ping)):
        p = ping[j].strip().split(' ')
        pt = time.mktime(time.strptime(p[0]+" "+p[1], "%Y-%m-%d %H:%M:%S"))
        if (pt &gt; fnt):
            break
        j = j + 1
        if (pt &gt;= ft - 10):
            po = p[8]
            break

    print f[0], f[1], int(float(f[6])/1000), int(float(q[6])/1000), po
</code></pre>

<pre><code>
分时段统计res2.py:
</code></pre>

<pre><code>#coding:utf-8

r = open('res_out').readlines()

hs1 = {}
hs2 = {}
hsw = {}
hl = {}
hr = {}
hm = {}

for line in r:
    arr = line.strip().split(' ')
    h1 = int(arr[1][0:2])
    if h1 &gt;= 2 and h1 &lt;= 9:
        h2 = "H2-9"
    else:
        h2 = "H10-25"
    h3 = 'Hall'
    for h in (h1, h2, h3):
        if h not in hsw:
            hs1[h] = hs2[h] = hsw[h] = hl[h] = hr[h] = hm[h] = 0
        hs1[h] += int(arr[2])
        hs2[h] += int(arr[3])
        hsw[h] += 1
        hl[h] += int(arr[4][0:-1])
        hr[h] += int(arr[5])
        hm[h] += int(arr[6])

print "时段", "下载次数", "ff(KB/s)", "qq(KB/s)", "提升比例", "丢包率", "recovery_skb", "mark_skb"
for h in sorted(hs1.keys()):
    s1 = hs1[h]/hsw[h]
    s2 = hs2[h]/hsw[h]
    s3 = hl[h]/hsw[h]
    s4 = hr[h]/hsw[h]
    s5 = hm[h]/hsw[h]
    #print h, hsw[h], s1, s2, 100*(s1-s2)/s2, s3, s4, s5
    print "%s\t%d\t%d\t%d\t%d\t%d\t%d\t%d" % (h, hsw[h], s1, s2, 100*(s1-s2)/s2, s3, s4, s5)
</code></pre>

<pre><code>
#### 一、http_load
http_load以并行复用的方式运行，用以测试web服务器的吞吐量与负载。但是它不同于大多数压力测试工具，它可以以一个单一的进程运行，一般不会把客户机搞死。还可以测试HTTPS类的网站请求。

下载地址：http://www.acme.com/software/http_load/
</code></pre>

<pre><code>./http_load -verbose -proxy 192.168.99.6:80 -parallel 24 -seconds 1000 url.txt
</code></pre>

<pre><code>
[http_load 改进版下载 http_load-09Mar2016-kk.tar.gz](/download/tools/http_load-09Mar2016-kk.tar.gz)  
改进点：  
2018-01-19:  
1. 异常时打印更多信息("want_bytes=%ld got_bytes=%ld sport=%d connect_at=%ld now=%ld last=%ld")  
2. http1.0 改成 http1.1 支持多次request  
3. 增加 [ -requests times ] 参数, 在一条流中会发起times次request, 默认为1  
2018-01-26:  
4. 增加 [ -fastopen ] 参数，http协议增加fastopen测试，fastopen连接时改为阻塞模式。非阻塞模式syn无法附带数据  
2018-04-12:  
5. 修复 num_connections 可能出现的统计错误，以及fastopen可能出现的请求超时  
2018-06-13:  
6. https增加SNI信息，Makefile默认开启https支持  
2019-02-19:  
7. 修复IPV6的bug  
2020-08-29:
8. fastopen 支持非阻塞模式-nonblock，但第一次连接还得用block


#### 二、webbench

webbench是Linux下的一个网站压力测试工具，最多可以模拟3万个并发连接去测试网站的负载能力。
</code></pre>

<pre><code>用法：webbench -c 并发数 -t 运行测试时间 URL
如：webbench -c 5000 -t 120 http://www.163.com
</code></pre>

<pre><code>
#### 三、ab
ab是apache自带的一款功能强大的测试工具。安装了apache一般就自带了，用法可以查看它的说明

参数众多，一般我们用到的是-n 和-c

例如：
</code></pre>

<pre><code>./ab -c 1000 -n 100 http://www.vpser.net/index.php
</code></pre>

<pre><code>这个表示同时处理1000个请求并运行100次index.php文件.

#### 四、Siege
一款开源的压力测试工具，可以根据配置对一个WEB站点进行多用户的并发访问，记录每个用户所有请求过程的相应时间，并在一定数量的并发访问下重复进行。
官方：http://www.joedog.org/

使用
</code></pre>

<pre><code>siege -c 200 -r 10 -f example.url
</code></pre>

<p>```</p>

<p>-c是并发量，-r是重复次数。 url文件就是一个文本，每行都是一个url，它会从里面随机访问的。</p>
]]></content>
  </entry>
  
</feed>
